<div class="home"><p>Currently Migrating into <a href="https://quarto.org/">Quarto</a> platform. See the progress on <a href="https://kcsgoodboy.github.io/">here</a> :)</p>

<h1 id="posts">Posts</h1>



  

  <!-- Hide posts if front matter flag hide:true -->
  
  

  <!-- Sort posts by rank, then date -->
  
  
  

 
  

   <!-- Assemble final sorted posts array -->
  
  <ul class="post-list"><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/LogReg_kiank.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/deeplearning.ai/2022/05/11/01-Logistic-Regression-with-a-Neural-Network.html">
            Logistic Regression with a Neural Network mindset
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will build a logistic regression classifier to recognize cats. This is the summary of lecture "Neural Networks and Deep Learning" from DeepLearning.AI. (slightly modified from original assignment)</p>
          <p class="post-meta">May 11, 2022</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/model_simpleQuadratic.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow/deeplearning.ai/2022/02/08/02-Tensorflow2-Custom-Layers.html">
            Custom Layers in Tensorflow 2
          </a>
        </h3>
        <p class="post-meta-description">Custom layers give you the flexibility to implement models that use non-standard layers. In this post, we will practice uilding off of existing standard layers to create custom layers for your models. This is the summary of lecture "Custom Models, Layers and Loss functions with Tensorflow" from DeepLearning.AI.</p>
          <p class="post-meta">Feb 8, 2022</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/huber_loss_ex.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow/deeplearning.ai/2022/02/08/01-Tensorflow2-Custom-Loss-Function.html">
            Custom Loss Function in Tensorflow 2.
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will learn how to build custom loss functions with function and class. This is the summary of lecture "Custom Models, Layers and Loss functions with Tensorflow" from DeepLearning.AI.</p>
          <p class="post-meta">Feb 8, 2022</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/fashion_mnist_siamese.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow/deeplearning.ai/2022/02/05/01-Tensorflow2-Functional-API.html">
            Practice with the Tensorflow 2 Functional API.
          </a>
        </h3>
        <p class="post-meta-description">In this post, it will demonstrate how to build models with the Functional syntax. You'll build one using the Sequential API and see how you can do the same with the Functional API. Both will arrive at the same architecture and you can train and evaluate it as usual. This is the summary of lecture "Custom Models, Layers and Loss functions with Tensorflow" from DeepLearning.AI.</p>
          <p class="post-meta">Feb 5, 2022</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/celeba-reconstruct.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/14/03-Variational-AutoEncoder-Celeb-A.html">
            VAE for the CelebA dataset
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will implement the variational AutoEncoder (VAE) for an image dataset of celebrity faces. This is the Programming Assignment of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 14, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/fashion_mnist_generated2.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/14/02-KL-divergence-layers.html">
            KL Divergence Layers
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will cover the easy way to handle KL divergence with tensorflow probability layer object. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 14, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/fashion_mnist_generated.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/14/01-Maximizing-the-ELBO.html">
            Maximizing the ELBO
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will cover the complete implementation of Variational AutoEncoder, which can optimize the ELBO objective function. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 14, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/kl_pq.gif" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/13/02-Minimizing-KL-Divergence.html">
            Minimizing Kullback-Leibler Divergence
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will see how the KL divergence can be computed between two distribution objects, in cases where an analytical expression for the KL divergence is known. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 13, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/mnist_reconstruction.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/13/01-Encoders-and-decoders.html">
            Encoders and decoders
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will implement simple autoencoder architecture. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 13, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/realnvp_lsun.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/08/02-RealNVP-for-the-LSUN-bedroom-dataset.html">
            RealNVP for the LSUN bedroom dataset
          </a>
        </h3>
        <p class="post-meta-description">In this post, we are take a look at an application for RealNVP. This is a homework assignment of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 8, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/trainable_dist.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/08/01-AutoRegressive-flows-and-RealNVP.html">
            AutoRegressive flows and RealNVP
          </a>
        </h3>
        <p class="post-meta-description">In this post, we are going to take a look at Autoregressive flows and RealNVP. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 8, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/learned_dist.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/07/02-subclassing-bijectors.html">
            Subclassing Bijectors
          </a>
        </h3>
        <p class="post-meta-description">In this post, we are going to make customized transformation with our own bijectors for fexibility. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 7, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/transformed_dist.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/09/07/01-the-transformedDistribution-class.html">
            The TransformedDistribution class
          </a>
        </h3>
        <p class="post-meta-description">In this post, we are going to take a look at transform distribution objects as a module. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Sep 7, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/gumbelCDF.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/08/30/01-bijectors.html">
            Bijectors
          </a>
        </h3>
        <p class="post-meta-description">In this post, we are going to take a look at bijectors which are the objects intense flow probability that implemented by bijective or invertible transformations. This is the summary of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Aug 30, 2021</p>
      </div>
  </div></li><li><div class="Box box-shadow-medium rounded-1 col-12"><div class="col-4 d-table-cell p-3 v-align-middle">
        <img class="image-preview " src="/images/mnist_corrupted.png" />
      </div><div class="col-8 d-table-cell p-3">
        <h3>
          <a class="post-link" href="/python/coursera/tensorflow_probability/icl/2021/08/26/01-Bayesian-Convolutional-Neural-Network.html">
            Bayesian Convolutional Neural Network
          </a>
        </h3>
        <p class="post-meta-description">In this post, we will create a Bayesian convolutional neural network to classify the famous MNIST handwritten digits. This will be a probabilistic model, designed to capture both aleatoric and epistemic uncertainty. You will test the uncertainty quantifications against a corrupted version of the dataset. This is the assignment of lecture "Probabilistic Deep Learning with Tensorflow 2" from Imperial College London.</p>
          <p class="post-meta">Aug 26, 2021</p>
      </div>
  </div></li></ul>

    
      <div class="pager">
        <ul class="pagination">
          <li><div class="pager-edge">â€¢</div></li>
          <li><div class="current-page">1</div></li>
          <li><a href="/page2/" class="next-page">2</a></li>
        </ul>
      </div></div>