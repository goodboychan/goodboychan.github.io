<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Softmax Regression | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Softmax Regression" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this post, it will cover the basic concept of softmax regression, also known as multinomial classification. And it will explain what the hypothesis and cost function, and how to solve it with gradient descent as we saw previously. Also we will try to implement it with tensorflow 2.x" />
<meta property="og:description" content="In this post, it will cover the basic concept of softmax regression, also known as multinomial classification. And it will explain what the hypothesis and cost function, and how to solve it with gradient descent as we saw previously. Also we will try to implement it with tensorflow 2.x" />
<link rel="canonical" href="https://goodboychan.github.io/chans_jupyter/python/tensorflow/machine_learning/2020/09/10/01-Softmax-Regression.html" />
<meta property="og:url" content="https://goodboychan.github.io/chans_jupyter/python/tensorflow/machine_learning/2020/09/10/01-Softmax-Regression.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:image" content="https://goodboychan.github.io/chans_jupyter/images/sigmoid.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-09-10T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://goodboychan.github.io/chans_jupyter/python/tensorflow/machine_learning/2020/09/10/01-Softmax-Regression.html","@type":"BlogPosting","headline":"Softmax Regression","dateModified":"2020-09-10T00:00:00-05:00","datePublished":"2020-09-10T00:00:00-05:00","image":"https://goodboychan.github.io/chans_jupyter/images/sigmoid.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/chans_jupyter/python/tensorflow/machine_learning/2020/09/10/01-Softmax-Regression.html"},"author":{"@type":"Person","name":"Chanseok Kang"},"description":"In this post, it will cover the basic concept of softmax regression, also known as multinomial classification. And it will explain what the hypothesis and cost function, and how to solve it with gradient descent as we saw previously. Also we will try to implement it with tensorflow 2.x","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/chans_jupyter/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/chans_jupyter/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<script>(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)})(window,document,'script','//www.google-analytics.com/analytics.js','ga');ga('create','UA-33905785-1','auto');ga('require','displayfeatures');ga('send','pageview');</script>

<link rel="shortcut icon" type="image/x-icon" href="/chans_jupyter/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/chans_jupyter/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/chans_jupyter/about/">About Me</a><a class="page-link" href="/chans_jupyter/search/">Search</a><a class="page-link" href="/chans_jupyter/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Softmax Regression</h1><p class="page-description">In this post, it will cover the basic concept of softmax regression, also known as multinomial classification. And it will explain what the hypothesis and cost function, and how to solve it with gradient descent as we saw previously. Also we will try to implement it with tensorflow 2.x</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-10T00:00:00-05:00" itemprop="datePublished">
        Sep 10, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      13 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/chans_jupyter/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/chans_jupyter/categories/#Tensorflow">Tensorflow</a>
        &nbsp;
      
        <a class="category-tags-link" href="/chans_jupyter/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/goodboychan/chans_jupyter/tree/main/_notebooks/2020-09-10-01-Softmax-Regression.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/chans_jupyter/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/chans_jupyter/main?filepath=_notebooks%2F2020-09-10-01-Softmax-Regression.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/chans_jupyter/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/chans_jupyter/blob/main/_notebooks/2020-09-10-01-Softmax-Regression.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/chans_jupyter/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Logistic-Regression">Logistic Regression </a></li>
<li class="toc-entry toc-h2"><a href="#Multinomial-Classification">Multinomial Classification </a></li>
<li class="toc-entry toc-h2"><a href="#Softmax-function">Softmax function </a></li>
<li class="toc-entry toc-h2"><a href="#Cost-function-of-Multinomial-classification">Cost function of Multinomial classification </a></li>
<li class="toc-entry toc-h2"><a href="#Implment-with-Tensorflow">Implment with Tensorflow </a></li>
<li class="toc-entry toc-h2"><a href="#Softmax-Regression-for-animal-classification">Softmax Regression for animal classification </a></li>
<li class="toc-entry toc-h2"><a href="#Summary">Summary </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-09-10-01-Softmax-Regression.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">tensorflow</span> <span class="k">as</span> <span class="nn">tf</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">16</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'text.usetex'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rc</span><span class="p">(</span><span class="s1">'font'</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">15</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Logistic-Regression">
<a class="anchor" href="#Logistic-Regression" aria-hidden="true"><span class="octicon octicon-link"></span></a>Logistic Regression<a class="anchor-link" href="#Logistic-Regression"> </a>
</h2>
<p>Previously, we covered logistic regression, which can handle the classification task, especially on binary classification. Basic concept of logistic regression is the same as the one in linear regression. For the simplicity, we omit the bias term.</p>
<p>
$$ H_{\theta}(X) = \theta^TX $$
</p>
<p>But we need to classify the data, not predict the value. So we tried to predict the probability of whether it is True or False, and decided the label based on decision boundary. So we introduced new type of hypothesis, the sigmoid (or logistic) function.</p>
<p>
$$ g(z) = \frac{1}{1 + e^{-z}} $$
</p>
<p>Its output range is from 0 to 1. So it is reasonable choice to calculate the probability. All we need to do it calculating the original hypothesis ($H_{\theta}(X)$) and use it in sigmoid function as an argument. ($g(H_{\theta}(X)$)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mf">0.1</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">z</span><span class="p">))</span>

<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">8</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">'red'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">'$z$'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">'$y$'</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">'Sigmoid function $g(z)$'</span><span class="p">);</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's the way how we can handle the binary classification. Then how can we apply it multinomial classification that have more than two labels to classify?</p>
<h2 id="Multinomial-Classification">
<a class="anchor" href="#Multinomial-Classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Multinomial Classification<a class="anchor-link" href="#Multinomial-Classification"> </a>
</h2>
<p>Actually, Multinomial classification is the extended version of binary classification. Suppose we have three labels, $A, B, C$, And we don't know the trick of multinomial classification. how can we classfity them?</p>
<p>The simplest method is divide and conquer. We can divide the big problem into three small problem like,</p>
<ul>
<li>Whether it is $A$ or not.</li>
<li>Whether it is $B$ or not.</li>
<li>Whether it is $C$ or not.</li>
</ul>
<p>The hypothesis of binary classification is to predict the probability. So we can combine the three hypothesis of binary classification.</p>
<p>
$$ \begin{aligned} H_{\theta}(X) = WX &amp;= \begin{bmatrix} w_{11} &amp; w_{12} &amp; w_{13} \\ w_{21} &amp; w_{22} &amp; w_{23} \\ w_{31} &amp; w_{32} &amp; w_{33} \end{bmatrix} \cdot \begin{bmatrix} x_1 \\ x_2 \\ x_3 \end{bmatrix} \\ &amp;= \begin{bmatrix} w_{11} x_1 + w_{12} x_2 + w_{13} x_3 \\ w_{21} x_1 + w_{22} x_2 + w_{23} x_3 \\ w_{31} x_1 + w_{32} x_2 + w_{33} x_3 \end{bmatrix} = \begin{bmatrix} \bar{y_{A}} \\ \bar{y_{B}} \\ \bar{y_{C}} \end{bmatrix} \end{aligned} $$
</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>It's (3,1) matrix. And the shape of output applying sigmoid function will also (3,1) matrix. What does it mean of each row? If we apply the sigmoid function on each row, It'll be the probability of whether it is True or False. So the first element is the probability of whether it is $A$ or not, and so on. All we have to do is applying sigmoid function on each row, right?</p>
<h2 id="Softmax-function">
<a class="anchor" href="#Softmax-function" aria-hidden="true"><span class="octicon octicon-link"></span></a>Softmax function<a class="anchor-link" href="#Softmax-function"> </a>
</h2>
<p>It will work, eventually. But there is more effective way to calculate the probability. If we apply the sigmoid on each value, let's say the probability of $A$ is 0.55, and $B$ is 0.66%, and $C$ is 0.44. How can we classify it. It has high probability of $B$, but we cannot ignore the probability of $A$ and $C$. So this kind of result is hard to interpret what label it is.</p>
<p>There is the way to calculate the probability of all, that sums up to 1. He we introduce the new additional function the <strong>softmax function</strong>.</p>
<p>
$$ \sigma(y_i) = \frac{e^{y_i}}{\sum_{j=1}^{K} e^{y_j}}  $$
</p>
<p>The rule of softmax function is to convert the score (the output of matrix multiplication) to probability. And Sum of all probability is 1. All we need to do is find the maximum probability of each row, define its labels. Usually, it can be calculated with argmax function, that is to find the argument to make maximum of its value.</p>
<h2 id="Cost-function-of-Multinomial-classification">
<a class="anchor" href="#Cost-function-of-Multinomial-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cost function of Multinomial classification<a class="anchor-link" href="#Cost-function-of-Multinomial-classification"> </a>
</h2>
<p>We can bring the cost function of binary classification here, the cross-entropy.</p>
$$ \text{C.E.} = -y\log(p) - (1-y)\log(1-p) $$<p>.</p>
<p>In multinomial classification, we can modify the cross entropy function.</p>
<p>
$$ \text{C.E.} = -\sum_{i} y_i \log (\bar{y_i}) $$
</p>
<p>The rule of cost function is measure the score of classification. So if the model incorrectly classify the label, cost function must return the low cost, and cost function must give the high cost if it is correctly classified. Even if it is in the case of multinomial classification, it can apply it with same manner.</p>
<p>As a result, we define the cost function. And we can apply gradient descent to find weight vector to make the cost minimum.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implment-with-Tensorflow">
<a class="anchor" href="#Implment-with-Tensorflow" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implment with Tensorflow<a class="anchor-link" href="#Implment-with-Tensorflow"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We will try to implment softmax regression with simple dataset. First, define the dataset.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">x_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">2</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">4</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">4</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">,</span> <span class="mi">6</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">,</span> <span class="mi">7</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>

<span class="n">y_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
    <span class="p">[[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We have three classes, but for the simplicity, <code>y_data</code> is modified with one-hot encoding.
And we need to initialize Weight vector $W$ and bias $b$. Usually, it initializes with random value from normal distribution.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="n">x_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">y_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">])),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'weight'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">((</span><span class="n">y_data</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">)),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'bias'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;tf.Variable 'weight:0' shape=(4, 3) dtype=float32, numpy=
array([[-0.03031273, -1.060833  , -1.20091   ],
       [-0.5629968 , -0.50404245,  1.4590237 ],
       [-1.2940224 , -0.48054248, -0.13930833],
       [-0.31837052, -0.72089845, -1.0884795 ]], dtype=float32)&gt; &lt;tf.Variable 'bias:0' shape=(3,) dtype=float32, numpy=array([ 0.25864193,  1.4588804 , -1.203377  ], dtype=float32)&gt;
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Then, we can define the softmax function with tensorflow. Of course, you can implement it manually with numpy, but tensorflow also offers softmax fuction as an API.</p>
<div class="highlight"><pre><span></span><span class="n">h</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Test it with sample data,</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="n">x_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]]))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">softmax</span><span class="p">([</span><span class="n">x_data</span><span class="p">[</span><span class="mi">0</span><span class="p">]])</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span><span class="o">.</span><span class="n">sum</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tf.Tensor([[0.11066143 0.22252838 0.66681015]], shape=(1, 3), dtype=float32)
1.0
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>We can also define the cost function and gradient function.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">cost</span> <span class="o">=</span> <span class="o">-</span><span class="n">tf</span><span class="o">.</span><span class="n">reduce_sum</span><span class="p">(</span><span class="n">Y</span> <span class="o">*</span> <span class="n">tf</span><span class="o">.</span><span class="n">math</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">logits</span><span class="p">),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">cost_mean</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">cost</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">cost_mean</span>

<span class="k">def</span> <span class="nf">gradient</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="p">[</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">])</span>
    <span class="k">return</span> <span class="n">grads</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Finally, we implement the training step.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">5000</span><span class="p">):</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">gradient</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads_and_vars</span><span class="o">=</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="p">[</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">]))</span>
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">500</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">{}</span><span class="s1">, Loss: </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">x_data</span><span class="p">,</span> <span class="n">y_data</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch: 0, Loss: 5.2738
Epoch: 500, Loss: 0.7892
Epoch: 1000, Loss: 0.6457
Epoch: 1500, Loss: 0.5712
Epoch: 2000, Loss: 0.5234
Epoch: 2500, Loss: 0.4884
Epoch: 3000, Loss: 0.4606
Epoch: 3500, Loss: 0.4373
Epoch: 4000, Loss: 0.4171
Epoch: 4500, Loss: 0.3993
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To check the model performance, we need to check validity.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">b</span> <span class="o">=</span> <span class="n">softmax</span><span class="p">(</span><span class="n">x_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y_data</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>tf.Tensor([2 2 2 1 0 1 0 0], shape=(8,), dtype=int64)
tf.Tensor([2 2 2 1 1 1 0 0], shape=(8,), dtype=int64)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Compare the predicted result with actual data, we can find that one data is mis-classified, but most of data are correctly classified.</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Softmax-Regression-for-animal-classification">
<a class="anchor" href="#Softmax-Regression-for-animal-classification" aria-hidden="true"><span class="octicon octicon-link"></span></a>Softmax Regression for animal classification<a class="anchor-link" href="#Softmax-Regression-for-animal-classification"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>In this section, we apply softmax regressino animal classification. The dataset is from <a href="https://archive.ics.uci.edu/ml/datasets/Zoo">UCI ML Repository</a>.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/zoo.data'</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>aardvark</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>antelope</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>bass</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>bear</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>boar</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>But in our case, we don't need the name of each animals. We want to classify animal's type, regardless of name.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>1</td>
      <td>0</td>
      <td>0</td>
      <td>4</td>
      <td>1</td>
      <td>0</td>
      <td>1</td>
      <td>1</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And when we look at the label of data (the 17th column), we can find that the range is from 1 to 7. we need to shift it by 1.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 101 entries, 0 to 100
Data columns (total 17 columns):
 #   Column  Non-Null Count  Dtype
---  ------  --------------  -----
 0   1       101 non-null    int64
 1   2       101 non-null    int64
 2   3       101 non-null    int64
 3   4       101 non-null    int64
 4   5       101 non-null    int64
 5   6       101 non-null    int64
 6   7       101 non-null    int64
 7   8       101 non-null    int64
 8   9       101 non-null    int64
 9   10      101 non-null    int64
 10  11      101 non-null    int64
 11  12      101 non-null    int64
 12  13      101 non-null    int64
 13  14      101 non-null    int64
 14  15      101 non-null    int64
 15  16      101 non-null    int64
 16  17      101 non-null    int64
dtypes: int64(17)
memory usage: 13.5 KB
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.425743</td>
      <td>0.198020</td>
      <td>0.584158</td>
      <td>0.405941</td>
      <td>0.237624</td>
      <td>0.356436</td>
      <td>0.554455</td>
      <td>0.603960</td>
      <td>0.821782</td>
      <td>0.792079</td>
      <td>0.079208</td>
      <td>0.168317</td>
      <td>2.841584</td>
      <td>0.742574</td>
      <td>0.128713</td>
      <td>0.435644</td>
      <td>2.831683</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.496921</td>
      <td>0.400495</td>
      <td>0.495325</td>
      <td>0.493522</td>
      <td>0.427750</td>
      <td>0.481335</td>
      <td>0.499505</td>
      <td>0.491512</td>
      <td>0.384605</td>
      <td>0.407844</td>
      <td>0.271410</td>
      <td>0.376013</td>
      <td>2.033385</td>
      <td>0.439397</td>
      <td>0.336552</td>
      <td>0.498314</td>
      <td>2.102709</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>4.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>7.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">df</span><span class="p">[</span><span class="mi">17</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="mi">17</span><span class="p">]</span> <span class="o">-</span> <span class="mi">1</span>
<span class="n">df</span><span class="o">.</span><span class="n">describe</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>count</th>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
      <td>101.000000</td>
    </tr>
    <tr>
      <th>mean</th>
      <td>0.425743</td>
      <td>0.198020</td>
      <td>0.584158</td>
      <td>0.405941</td>
      <td>0.237624</td>
      <td>0.356436</td>
      <td>0.554455</td>
      <td>0.603960</td>
      <td>0.821782</td>
      <td>0.792079</td>
      <td>0.079208</td>
      <td>0.168317</td>
      <td>2.841584</td>
      <td>0.742574</td>
      <td>0.128713</td>
      <td>0.435644</td>
      <td>1.831683</td>
    </tr>
    <tr>
      <th>std</th>
      <td>0.496921</td>
      <td>0.400495</td>
      <td>0.495325</td>
      <td>0.493522</td>
      <td>0.427750</td>
      <td>0.481335</td>
      <td>0.499505</td>
      <td>0.491512</td>
      <td>0.384605</td>
      <td>0.407844</td>
      <td>0.271410</td>
      <td>0.376013</td>
      <td>2.033385</td>
      <td>0.439397</td>
      <td>0.336552</td>
      <td>0.498314</td>
      <td>2.102709</td>
    </tr>
    <tr>
      <th>min</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>25%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>2.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>50%</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
    </tr>
    <tr>
      <th>75%</th>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>4.000000</td>
      <td>1.000000</td>
      <td>0.000000</td>
      <td>1.000000</td>
      <td>3.000000</td>
    </tr>
    <tr>
      <th>max</th>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>8.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>1.000000</td>
      <td>6.000000</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And as you can see from the contents, we need to convert the numeric data with one-hot encoding. Tensorflow offers some APIs for one-hot encoding.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]]</span><span class="o">.</span><span class="n">to_numpy</span><span class="p">()</span>

<span class="c1"># Make y data with onehot encoding</span>
<span class="n">Y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">y</span><span class="p">),</span> <span class="n">depth</span><span class="o">=</span><span class="mi">7</span><span class="p">)</span>
<span class="n">Y_one_hot</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">Y_one_hot</span><span class="p">,</span> <span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">7</span><span class="p">])</span>
<span class="nb">print</span><span class="p">(</span><span class="n">Y_one_hot</span><span class="p">[:</span><span class="mi">3</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="n">y</span><span class="p">[:</span><span class="mi">3</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[1. 0. 0. 0. 0. 0. 0.]
 [1. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 1. 0. 0. 0.]]
[[0]
 [0]
 [3]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p></p>
<div class="flash">
    <svg class="octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info octicon octicon-info" viewbox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M8 1.5a6.5 6.5 0 100 13 6.5 6.5 0 000-13zM0 8a8 8 0 1116 0A8 8 0 010 8zm6.5-.25A.75.75 0 017.25 7h1a.75.75 0 01.75.75v2.75h.25a.75.75 0 010 1.5h-2a.75.75 0 010-1.5h.25v-2h-.25a.75.75 0 01-.75-.75zM8 6a1 1 0 100-2 1 1 0 000 2z"></path></svg>
    <strong>Note: </strong>When we try to use tf.one_hot, keep in mind that, If the input indices is rank $N$, the output will have rank $N+1$. The new axis is created at dimension axis. (default case: the new axis is appended at the end) (<a href="https://www.tensorflow.org/api_docs/python/tf/one_hot">link</a>). So you must reshape it to maintain the shape of matrix.
</div>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>All tasks we have done is a part of data preprocessing. So now it is the time to building dataset, and implement the learning process.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">W</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="n">X</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">7</span><span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'weight'</span><span class="p">)</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">Variable</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">([</span><span class="mi">7</span><span class="p">,</span> <span class="p">]),</span> <span class="n">name</span><span class="o">=</span><span class="s1">'bias'</span><span class="p">)</span>
<span class="n">variables</span> <span class="o">=</span> <span class="p">[</span><span class="n">W</span><span class="p">,</span> <span class="n">b</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Previously, we built the softmax function and cost function(cross entropy) manually, But the Tensorflow also made a fancy API to do it once. As we define the logit function ($H_{\theta}(X)$) and labels, we can use it for tensorflow API.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">logit_fn</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">W</span><span class="p">)</span> <span class="o">+</span> <span class="n">b</span>

<span class="c1"># Softmax function </span>
<span class="k">def</span> <span class="nf">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">logit_fn</span><span class="p">(</span><span class="n">X</span><span class="p">))</span>

<span class="c1"># Loss function for cross entropy</span>
<span class="k">def</span> <span class="nf">loss_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">logits</span> <span class="o">=</span> <span class="n">logit_fn</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">cost_i</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">softmax_cross_entropy_with_logits</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="n">y</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">cost_i</span><span class="p">)</span>

<span class="c1"># Calculate gradient</span>
<span class="k">def</span> <span class="nf">grad_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="k">with</span> <span class="n">tf</span><span class="o">.</span><span class="n">GradientTape</span><span class="p">()</span> <span class="k">as</span> <span class="n">tape</span><span class="p">:</span>
        <span class="n">loss</span> <span class="o">=</span> <span class="n">loss_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">tape</span><span class="o">.</span><span class="n">gradient</span><span class="p">(</span><span class="n">loss</span><span class="p">,</span> <span class="n">variables</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">grads</span>

<span class="c1"># Predict function for validation</span>
<span class="k">def</span> <span class="nf">prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
    <span class="n">pred</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">softmax</span><span class="p">(</span><span class="n">X</span><span class="p">),</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">correct</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">equal</span><span class="p">(</span><span class="n">pred</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">accuracy</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">reduce_mean</span><span class="p">(</span><span class="n">tf</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="n">correct</span><span class="p">,</span> <span class="n">tf</span><span class="o">.</span><span class="n">float32</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">accuracy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">tf</span><span class="o">.</span><span class="n">keras</span><span class="o">.</span><span class="n">optimizers</span><span class="o">.</span><span class="n">SGD</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">e</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">2000</span><span class="p">):</span>
    <span class="n">grads</span> <span class="o">=</span> <span class="n">grad_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_one_hot</span><span class="p">)</span>
    <span class="n">optimizer</span><span class="o">.</span><span class="n">apply_gradients</span><span class="p">(</span><span class="n">grads_and_vars</span><span class="o">=</span><span class="nb">zip</span><span class="p">(</span><span class="n">grads</span><span class="p">,</span> <span class="n">variables</span><span class="p">))</span>
    
    <span class="k">if</span> <span class="n">e</span> <span class="o">%</span> <span class="mi">100</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'Epoch: </span><span class="si">{}</span><span class="s1">, Loss: </span><span class="si">{:.4f}</span><span class="s1">, Acc: </span><span class="si">{:.4f}</span><span class="s1">'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">e</span><span class="p">,</span> 
                                                            <span class="n">loss_fn</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">(),</span> 
                                                            <span class="n">prediction</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">Y_one_hot</span><span class="p">)</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Epoch: 0, Loss: 6.8638, Acc: 0.0990
Epoch: 100, Loss: 0.7650, Acc: 0.8218
Epoch: 200, Loss: 0.5063, Acc: 0.8713
Epoch: 300, Loss: 0.3788, Acc: 0.9109
Epoch: 400, Loss: 0.2988, Acc: 0.9208
Epoch: 500, Loss: 0.2443, Acc: 0.9406
Epoch: 600, Loss: 0.2055, Acc: 0.9505
Epoch: 700, Loss: 0.1766, Acc: 0.9505
Epoch: 800, Loss: 0.1543, Acc: 0.9505
Epoch: 900, Loss: 0.1366, Acc: 0.9604
Epoch: 1000, Loss: 0.1224, Acc: 0.9802
Epoch: 1100, Loss: 0.1107, Acc: 0.9901
Epoch: 1200, Loss: 0.1009, Acc: 1.0000
Epoch: 1300, Loss: 0.0927, Acc: 1.0000
Epoch: 1400, Loss: 0.0857, Acc: 1.0000
Epoch: 1500, Loss: 0.0797, Acc: 1.0000
Epoch: 1600, Loss: 0.0745, Acc: 1.0000
Epoch: 1700, Loss: 0.0699, Acc: 1.0000
Epoch: 1800, Loss: 0.0659, Acc: 1.0000
Epoch: 1900, Loss: 0.0623, Acc: 1.0000
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Summary">
<a class="anchor" href="#Summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>Summary<a class="anchor-link" href="#Summary"> </a>
</h2>
<p>In this post, we covered the softmax function for multinomial classification. Actually, Multinomial classification is extended version of binary classification, so we can apply almost same approach of logistic regression here. But, to easily interpret the result, we substitute sigmoid function to softmax, and get the probability of each labels. We can also implement it with tensorflow 2.x.</p>

</div>
</div>
</div>
</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/chans_jupyter"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/chans_jupyter/python/tensorflow/machine_learning/2020/09/10/01-Softmax-Regression.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/chans_jupyter/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/chans_jupyter/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/chans_jupyter/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/goodboychan" title="goodboychan"><svg class="svg-icon grey"><use xlink:href="/chans_jupyter/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chanseokk" title="chanseokk"><svg class="svg-icon grey"><use xlink:href="/chans_jupyter/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/chans_jupyter/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
