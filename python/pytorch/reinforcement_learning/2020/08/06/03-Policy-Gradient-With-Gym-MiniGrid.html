<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Policy Gradient with gym-MiniGrid | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Policy Gradient with gym-MiniGrid" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="In this session, it will show the pytorch-implemented Policy Gradient in Gym-MiniGrid Environment. Through this, you will know how to implement Vanila Policy Gradient (also known as REINFORCE), and test it on open source RL environment." />
<meta property="og:description" content="In this session, it will show the pytorch-implemented Policy Gradient in Gym-MiniGrid Environment. Through this, you will know how to implement Vanila Policy Gradient (also known as REINFORCE), and test it on open source RL environment." />
<link rel="canonical" href="https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:image" content="https://goodboychan.github.io/images/Minigrid_sample.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-08-06T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"In this session, it will show the pytorch-implemented Policy Gradient in Gym-MiniGrid Environment. Through this, you will know how to implement Vanila Policy Gradient (also known as REINFORCE), and test it on open source RL environment.","url":"https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html","@type":"BlogPosting","headline":"Policy Gradient with gym-MiniGrid","dateModified":"2020-08-06T00:00:00-05:00","datePublished":"2020-08-06T00:00:00-05:00","author":{"@type":"Person","name":"Chanseok Kang"},"image":"https://goodboychan.github.io/images/Minigrid_sample.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Policy Gradient with gym-MiniGrid</h1><p class="page-description">In this session, it will show the pytorch-implemented Policy Gradient in Gym-MiniGrid Environment.  Through this, you will know how to implement Vanila Policy Gradient (also known as REINFORCE), and test it on open source RL environment.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-08-06T00:00:00-05:00" itemprop="datePublished">
        Aug 6, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      14 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#PyTorch">PyTorch</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Reinforcement_Learning">Reinforcement_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Basic-Jupyter-Setting">Basic Jupyter Setting </a></li>
<li class="toc-entry toc-h2"><a href="#Setup-the-environment">Setup the environment </a></li>
<li class="toc-entry toc-h2"><a href="#Test-with-Random-Policy">Test with Random Policy </a></li>
<li class="toc-entry toc-h2"><a href="#Implement-Rollout-Buffer">Implement Rollout Buffer </a></li>
<li class="toc-entry toc-h2"><a href="#Construct-Policy-Network">Construct Policy Network </a></li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-08-06-03-Policy-Gradient-With-Gym-MiniGrid.ipynb
-->

<div class="container" id="notebook-container">
        
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Basic-Jupyter-Setting">
<a class="anchor" href="#Basic-Jupyter-Setting" aria-hidden="true"><span class="octicon octicon-link"></span></a>Basic Jupyter Setting<a class="anchor-link" href="#Basic-Jupyter-Setting"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pprint</span> <span class="kn">import</span> <span class="n">pprint</span>

<span class="o">%</span><span class="k">matplotlib</span> inline
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mf">10.0</span><span class="p">,</span> <span class="mf">8.0</span><span class="p">)</span> <span class="c1"># set default size of plots</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'image.interpolation'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'nearest'</span>
<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'image.cmap'</span><span class="p">]</span> <span class="o">=</span> <span class="s1">'gray'</span>

<span class="c1"># for auto-reloading external modules</span>
<span class="c1"># see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython</span>
<span class="o">%</span><span class="k">load_ext</span> autoreload
<span class="o">%</span><span class="k">autoreload</span> 2
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>The autoreload extension is already loaded. To reload it, use:
  %reload_ext autoreload
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Setup-the-environment">
<a class="anchor" href="#Setup-the-environment" aria-hidden="true"><span class="octicon octicon-link"></span></a>Setup the environment<a class="anchor-link" href="#Setup-the-environment"> </a>
</h2>
<p>Gridworld is widely used in RL environment. <a href="https://github.com/maximecb/gym-minigrid">Gym-MiniGrid</a> is custom GridWorld environment of OpenAI <a href="https://github.com/openai/gym">gym</a> style. Before dive in this environment, you need to install both of them.</p>

<pre><code>pip install gym
pip install gym-minigrid</code></pre>
<p>At first, Let's look at some frames of MiniGrid.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">import</span> <span class="nn">gym_minigrid</span>

<span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'MiniGrid-Empty-5x5-v0'</span><span class="p">)</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
<span class="n">before_img</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">'rgb_array'</span><span class="p">)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">forward</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
<span class="n">after_img</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">'rgb_array'</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">concatenate</span><span class="p">([</span><span class="n">before_img</span><span class="p">,</span> <span class="n">after_img</span><span class="p">],</span> <span class="mi">1</span><span class="p">));</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>This is the example of <code>MiniGrid-Empty-5x5-v0</code> environment. There are some blank cells, and gray obstacle which the agent cannot pass it. And the green cell is the goal to reach. The ultimate goal of this environment (and most of RL problem) is to find the optimal policy with highest reward. In this case, well-trained agent should find the optimal path to reach the goal.</p>
<p>Let's move to more larger environment <code>MiniGrid-Empty-8x8-v0</code>, and find the information what we can get.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'MiniGrid-Empty-8x8-v0'</span><span class="p">)</span>

<span class="c1"># Reset the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Select the action right (sample action)</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">right</span>

<span class="c1"># Take a step in the environment and store it in appropriate variables</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

<span class="c1"># Render the current state of the environment</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">'rgb_array'</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Observation:'</span><span class="p">,</span> <span class="n">obs</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Reward:'</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Done:'</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Info:'</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Image shape:'</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Observation: {'image': array([[[2, 5, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0]],

       [[2, 5, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0]],

       [[2, 5, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0]],

       [[2, 5, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0],
        [1, 0, 0]],

       [[2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0]],

       [[2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0]],

       [[2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0],
        [2, 5, 0]]], dtype=uint8), 'direction': 1, 'mission': 'get to the green goal square'}
Reward: 0
Done: False
Info: {}
Image shape: (256, 256, 3)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As the agent take an action, environment (MiniGrid) will be changed with respect to action. 
If the agent want to find the optimal path, the agent should notice the difference between current state and next state while taking an action. To help this, the environment generates next state, reward, and terminal flags.</p>
<p>Some helper function offers to render the sample action in Jupyter Notebook.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">base64</span>
<span class="kn">import</span> <span class="nn">glob</span>
<span class="kn">import</span> <span class="nn">io</span>
<span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">HTML</span>
<span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">display</span> 

<span class="k">def</span> <span class="nf">show_video</span><span class="p">():</span>
    <span class="n">mp4list</span> <span class="o">=</span> <span class="n">glob</span><span class="o">.</span><span class="n">glob</span><span class="p">(</span><span class="s1">'video/*.mp4'</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">mp4list</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">mp4</span> <span class="o">=</span> <span class="n">mp4list</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">video</span> <span class="o">=</span> <span class="n">io</span><span class="o">.</span><span class="n">open</span><span class="p">(</span><span class="n">mp4</span><span class="p">,</span> <span class="s1">'r+b'</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
        <span class="n">encoded</span> <span class="o">=</span> <span class="n">base64</span><span class="o">.</span><span class="n">b64encode</span><span class="p">(</span><span class="n">video</span><span class="p">)</span>
        <span class="n">display</span><span class="o">.</span><span class="n">display</span><span class="p">(</span><span class="n">HTML</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="s1">'''&lt;video alt="test" autoplay </span>
<span class="s1">                loop controls style="height: 400px;"&gt;</span>
<span class="s1">                &lt;source src="data:video/mp4;base64,</span><span class="si">{0}</span><span class="s1">" type="video/mp4" /&gt;</span>
<span class="s1">             &lt;/video&gt;'''</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">encoded</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">'ascii'</span><span class="p">))))</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s2">"Could not find video"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>To help agent training easily, MiniGrid offers <code>FlatObsWrapper</code> for flattening observation (in other words, 1D array)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">gym</span>
<span class="kn">from</span> <span class="nn">gym</span> <span class="kn">import</span> <span class="n">spaces</span>
<span class="kn">from</span> <span class="nn">gym_minigrid.minigrid</span> <span class="kn">import</span> <span class="n">OBJECT_TO_IDX</span><span class="p">,</span> <span class="n">COLOR_TO_IDX</span>

<span class="n">max_env_steps</span> <span class="o">=</span> <span class="mi">50</span>

<span class="k">class</span> <span class="nc">FlatObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">core</span><span class="o">.</span><span class="n">ObservationWrapper</span><span class="p">):</span>
    <span class="sd">"""Fully observable gridworld returning a flat grid encoding."""</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">env</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">env</span><span class="p">)</span>

        <span class="c1"># Since the outer walls are always present, we remove left, right, top, bottom walls</span>
        <span class="c1"># from the observation space of the agent. There are 3 channels, but for simplicity</span>
        <span class="c1"># in this assignment, we will deal with flattened version of state.</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">observation_space</span> <span class="o">=</span> <span class="n">spaces</span><span class="o">.</span><span class="n">Box</span><span class="p">(</span>
            <span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
            <span class="n">high</span><span class="o">=</span><span class="mi">255</span><span class="p">,</span>
            <span class="n">shape</span><span class="o">=</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">width</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">env</span><span class="o">.</span><span class="n">height</span><span class="o">-</span><span class="mi">2</span><span class="p">)</span> <span class="o">*</span> <span class="mi">3</span><span class="p">,),</span>  <span class="c1"># number of cells</span>
            <span class="n">dtype</span><span class="o">=</span><span class="s1">'uint8'</span>
        <span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">max_steps</span> <span class="o">=</span> <span class="n">max_env_steps</span>

    <span class="k">def</span> <span class="nf">observation</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>
        <span class="c1"># this method is called in the step() function to get the observation</span>
        <span class="c1"># we provide code that gets the grid state and places the agent in it</span>
        <span class="n">env</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">unwrapped</span>
        <span class="n">full_grid</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">grid</span><span class="o">.</span><span class="n">encode</span><span class="p">()</span>
        <span class="n">full_grid</span><span class="p">[</span><span class="n">env</span><span class="o">.</span><span class="n">agent_pos</span><span class="p">[</span><span class="mi">0</span><span class="p">]][</span><span class="n">env</span><span class="o">.</span><span class="n">agent_pos</span><span class="p">[</span><span class="mi">1</span><span class="p">]]</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span>
            <span class="n">OBJECT_TO_IDX</span><span class="p">[</span><span class="s1">'agent'</span><span class="p">],</span>
            <span class="n">COLOR_TO_IDX</span><span class="p">[</span><span class="s1">'red'</span><span class="p">],</span>
            <span class="n">env</span><span class="o">.</span><span class="n">agent_dir</span>
        <span class="p">])</span>
        <span class="n">full_grid</span> <span class="o">=</span> <span class="n">full_grid</span><span class="p">[</span><span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>   <span class="c1"># remove outer walls of the environment (for efficiency)</span>
        
        <span class="n">flattened_grid</span> <span class="o">=</span> <span class="n">full_grid</span><span class="o">.</span><span class="n">ravel</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">flattened_grid</span>
    
    <span class="k">def</span> <span class="nf">render</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="sd">"""This removes the default visualization of the partially observable field of view."""</span>
        <span class="n">kwargs</span><span class="p">[</span><span class="s1">'highlight'</span><span class="p">]</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">unwrapped</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So It's time to run with sample action!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span> <span class="o">=</span> <span class="n">FlatObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="s1">'MiniGrid-Empty-8x8-v0'</span><span class="p">))</span>

<span class="c1"># Reset the environment</span>
<span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

<span class="c1"># Select the action right</span>
<span class="n">action</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">actions</span><span class="o">.</span><span class="n">right</span>

<span class="c1"># Take a step in the environment and store it in appropriate variables</span>
<span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

<span class="c1"># Render the current state of the environment</span>
<span class="n">img</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">render</span><span class="p">(</span><span class="s1">'rgb_array'</span><span class="p">)</span>
<span class="c1">################# YOUR CODE ENDS HERE ###############################</span>

<span class="nb">print</span><span class="p">(</span><span class="s1">'Observation:'</span><span class="p">,</span> <span class="n">obs</span><span class="p">,</span> <span class="s1">', Observation Shape: '</span><span class="p">,</span> <span class="n">obs</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Reward:'</span><span class="p">,</span> <span class="n">reward</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Done:'</span><span class="p">,</span> <span class="n">done</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Info:'</span><span class="p">,</span> <span class="n">info</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">'Image shape:'</span><span class="p">,</span> <span class="n">img</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">img</span><span class="p">);</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Observation: [10  0  1  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0
  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0
  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0
  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0  1  0  0
  1  0  0  1  0  0  1  0  0  8  1  0] , Observation Shape:  (108,)
Reward: 0
Done: False
Info: {}
Image shape: (256, 256, 3)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAdsAAAHVCAYAAAC5cFFEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVB0lEQVR4nO3dX4ild53n8c93jWPDJKBiG9wkrCK9MPFiozSuIiwOsqPmJuWFS7zQIPa0FxF015vojd4IXqwKwk7YWAYjOLoRFXMRZsYNggz4L5GgiVnXRrOmTUjWdVFZaYfE717UKbomVqe7q+rb59Tp1wuKc+p3nnPq9zz9mLfPc/5VdwcAmPMvlj0BAFh3YgsAw8QWAIaJLQAME1sAGCa2ADBsLLZV9Zaq+klVnaqq26b+DgCsupp4n21VPS/J/0zy75OcTvL9JO/o7h8f+B8DgBU3dWT72iSnuvtn3f1PSb6U5KahvwUAK+2Koce9JsljO34/neTfnmvhI0eO9FVXXTU0FQCY96tf/epX3X10t9umYlu7jP2z89VVdTLJySS58sors7GxMTQVAJi3ubn5v85129Rp5NNJrtvx+7VJHt+5QHff0d3Hu/v4kSNHhqYBAMs3FdvvJzlWVa+oqj9LcnOSe4b+FgCstJHTyN39dFW9L8nfJ3lekju7++GJvwUAq27qOdt0971J7p16fAA4LHyCFAAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGHbFsidwOdjc3Fz2FA7ciRMn1na9kvX7N1vX9UrWd93Wdb2Ss+t2OXFkCwDDxBYAhoktAAwTWwAYJrYr4u4kvcSfuxc/ABw8sQWAYd76syI+meTtS/77AMxwZAsAwxzZrojvJPn24vrrL+Hf3f6b37mEfxPgciO2K+TLi8tLGdsvn38RAPbJaWQAGObIdoV8anF5KV+s9KnzLwLAPjmyBYBhjmxX0PaR7X+6BH8DgHliu4K2X7Q0GVsvjAK4dJxGBoBhjmxX0PZ7Xr+dmbcBfTveVwtwKTmyBYBhYrvCpt6W4+0+AJeW08gr7MtJHltcv+4AHm/7sbw4CuDScmQLAMMc2a64g3wbkCNagOVwZAsAwxzZrrjtFzMdxJGtF0YBLIcjWwAYtq8j26p6NMnvkjyT5OnuPl5VL07y35K8PMmjSf5Dd//f/U3z8nV6cbn9fOvb9/AY2/c9/ZxLATDlII5s/7K7b+ju44vfb0tyX3cfS3Lf4nf26ZPZ+5cH7Oe+AOzfxGnkm5Lctbh+V5KNgb8BAIfGfl8g1Un+oao6yX/t7juSXN3dTyRJdz9RVS/d7yQ5+1nGj+XiPuDisfgcZIBl229s39Ddjy+C+o2q+h8XeseqOpnkZJJceeWV+5wGAKyufZ1G7u7HF5dPJflaktcmebKqXpYki8unznHfO7r7eHcfP3LkyH6mcVm52LfveLsPwPLtObZV9edVddX29SR/leShJPckuWWx2C1Jvr7fSXLWxX4KlE+NAli+/ZxGvjrJ16pq+3H+trv/rqq+n+TuqnpPkl9kb+9WAYC1sefYdvfPkvybXcb/T5I37WdSnNvpnH0bz3N9qtT2Mt5bC7B8PkEKAIb5bORD6EK+CchztQCrQ2wPoe33zX57cfn6Hbd9+1nLALB8TiMDwDBHtofY9qni1+8yBsDqcGQLAMMc2R5i258O9R93GQNgdTiyBYBhjmzXgOdpAVab2K4Bp44BVpvTyAAwzJHtGvD5xwCrzZEtAAwTWwAYJrYAMExsAWCY2ALAMLEFgGHV3cueQ44ePdobGxvLngYA7Nnm5uYD3X18t9u8z/YS2NzcXPYUDtyJEyfWdr2S9fs3W9f1StZ33dZ1vZKz63Y5cRoZAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADCsunvZc8jRo0d7Y2Nj2dMAgD3b3Nx8oLuP73abI1sAGHbFsidwOdjc3Fz2FA7ciRMn1na9kvX7N1vX9UrWd93Wdb2Ss+t2OXFkCwDDzhvbqrqzqp6qqod2jL24qr5RVT9dXL5oMV5V9emqOlVVP6yq10xOHgAOgws5sv1ckrc8a+y2JPd197Ek9y1+T5K3Jjm2+DmZ5PaDmSYAHF7njW13fyvJr581fFOSuxbX70qysWP8873lO0leWFUvO6jJAsBhtNfnbK/u7ieSZHH50sX4NUke27Hc6cUYAFy2DvoFUrXL2K5v5K2qk1V1f1Xdf+bMmQOeBgCsjr3G9snt08OLy6cW46eTXLdjuWuTPL7bA3T3Hd19vLuPHzlyZI/TAIDVt9fY3pPklsX1W5J8fcf4uxavSn5dkt9sn24GgMvVeT/Uoqq+mOSNSV5SVaeTfCTJx5PcXVXvSfKLJG9fLH5vkhuTnEry+yTvHpgzABwq541td7/jHDe9aZdlO8mt+50UAKwTnyAFAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsAwsQWAYWILAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsAwsQWAYWILAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsAwsQWAYWILAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsAwsQWAYWILAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsAwsQWAYWILAMOqu5c9hxw9erQ3NjaWPQ0A2LPNzc0Huvv4brc5sgWAYVcsewKXg83NzWVP4cCdOHFibdcrWb9/s3Vdr2R9121d1ys5u26XE0e2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGHbe2FbVnVX1VFU9tGPso1X1y6p6cPFz447bPlRVp6rqJ1X15qmJA8BhcSFHtp9L8pZdxj/V3Tcsfu5Nkqq6PsnNSV61uM/fVNXzDmqyAHAYnTe23f2tJL++wMe7KcmXuvsP3f3zJKeSvHYf8wOAQ28/z9m+r6p+uDjN/KLF2DVJHtuxzOnFGABctvYa29uTvDLJDUmeSPKJxXjtsmzv9gBVdbKq7q+q+8+cObPHaQDA6ttTbLv7ye5+prv/mOQzOXuq+HSS63Ysem2Sx8/xGHd09/HuPn7kyJG9TAMADoU9xbaqXrbj17cl2X6l8j1Jbq6qF1TVK5IcS/K9/U0RAA63K863QFV9Mckbk7ykqk4n+UiSN1bVDdk6RfxokvcmSXc/XFV3J/lxkqeT3Nrdz8xMHQAOh/PGtrvfscvwZ59j+Y8l+dh+JgUA68QnSAHAMLEFgGFiCwDDxBYAhoktAAwTWwAYJrYAMExsAWCY2ALAMLEFgGFiCwDDqnvXr5u9pI4ePdobGxvLngYA7Nnm5uYD3X18t9sc2QLAsPN+6w/7t7m5uewpHLgTJ06s7Xol6/dvtq7rlazvuq3reiVn1+1y4sgWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGFbdvew55OjRo72xsbHsaQCsjM3PbC57CmNO/PWJZU9hxObm5gPdfXy32xzZAsCwK5Y9gcvB5ub6/T/UEydOrO16Jev3b7au65Ws8bp9ZtkT4CA5sgWAYWILAMPEFgCGiS0ADBNbABgmtgAwTGwBYJjYAsCw88a2qq6rqm9W1SNV9XBVvX8x/uKq+kZV/XRx+aLFeFXVp6vqVFX9sKpeM70SALDKLuTI9ukkH+zuv0jyuiS3VtX1SW5Lcl93H0ty3+L3JHlrkmOLn5NJbj/wWQPAIXLe2Hb3E939g8X13yV5JMk1SW5KctdisbuSbH+TwE1JPt9bvpPkhVX1sgOfOQAcEhf1nG1VvTzJq5N8N8nV3f1EshXkJC9dLHZNksd23O30YgwALksXHNuqujLJV5J8oLt/+1yL7jL2J9/jV1Unq+r+qrr/zJkzFzoNADh0Lii2VfX8bIX2C9391cXwk9unhxeXTy3GTye5bsfdr03y+LMfs7vv6O7j3X38yJEje50/AKy8C3k1ciX5bJJHuvuTO266J8kti+u3JPn6jvF3LV6V/Lokv9k+3QwAl6ML+T7bNyR5Z5IfVdWDi7EPJ/l4krur6j1JfpHk7Yvb7k1yY5JTSX6f5N0HOmMAOGTOG9vu/sfs/jxskrxpl+U7ya37nBcArA2fIAUAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAMq+5e9hxy9OjR3tjYWPY0AGDPNjc3H+ju47vd5sgWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw8QWAIaJLQAME1sAGCa2ADBMbAFgmNgCwDCxBYBhYgsAw84b26q6rqq+WVWPVNXDVfX+xfhHq+qXVfXg4ufGHff5UFWdqqqfVNWbJ1cAAFbdFRewzNNJPtjdP6iqq5I8UFXfWNz2qe7+zzsXrqrrk9yc5FVJ/mWS/15V/7q7nznIiQPAYXHeI9vufqK7f7C4/rskjyS55jnuclOSL3X3H7r750lOJXntQUwWAA6ji3rOtqpenuTVSb67GHpfVf2wqu6sqhctxq5J8tiOu53OLnGuqpNVdX9V3X/mzJmLnjgAHBYXHNuqujLJV5J8oLt/m+T2JK9MckOSJ5J8YnvRXe7efzLQfUd3H+/u40eOHLnoiQPAYXFBsa2q52crtF/o7q8mSXc/2d3PdPcfk3wmZ08Vn05y3Y67X5vk8YObMgAcLhfyauRK8tkkj3T3J3eMv2zHYm9L8tDi+j1Jbq6qF1TVK5IcS/K9g5syABwuF/Jq5DckeWeSH1XVg4uxDyd5R1XdkK1TxI8meW+SdPfDVXV3kh9n65XMt3olMgCXs/PGtrv/Mbs/D3vvc9znY0k+to95AcDa8AlSADBMbAFgmNgCwDCxBYBh1f0nnzdx6SdR9b+T/L8kv1r2XNbMS2KbHjTb9ODZpgfPNj14F7JN/1V3H93thpWIbZJU1f3dfXzZ81gntunBs00Pnm168GzTg7ffbeo0MgAME1sAGLZKsb1j2RNYQ7bpwbNND55tevBs04O3r226Ms/ZAsC6WqUjWwBYSysR26p6S1X9pKpOVdVty57PYVRVj1bVj6rqwaq6fzH24qr6RlX9dHH5omXPc9VV1Z1V9VRVPbRjbNftWFs+vdhvf1hVr1nezFfTObbnR6vql4t99cGqunHHbR9abM+fVNWblzPr1VZV11XVN6vqkap6uKrevxi3n+7Rc2zTA9tXlx7bqnpekv+S5K1Jrs/Wtwldv9xZHVp/2d037Hh5+m1J7uvuY0nuW/zOc/tckrc8a+xc2/Gt2foKyWNJTia5/RLN8TD5XP50eybJpxb76g3dfW+SLP53f3OSVy3u8zeL/z7wzz2d5IPd/RdJXpfk1sW2s5/u3bm2aXJA++rSY5utL50/1d0/6+5/SvKlJDcteU7r4qYkdy2u35VkY4lzORS6+1tJfv2s4XNtx5uSfL63fCfJC5/1Pc+XvXNsz3O5KcmXuvsP3f3zJKey9d8HdujuJ7r7B4vrv0vySJJrYj/ds+fYpudy0fvqKsT2miSP7fj9dJ57JdldJ/mHqnqgqk4uxq7u7ieSrZ0pyUuXNrvD7Vzb0b67d+9bnNK8c8fTG7bnRaqqlyd5dZLvxn56IJ61TZMD2ldXIba7fVeul0hfvDd092uydcro1qr6d8ue0GXAvrs3tyd5ZZIbkjyR5BOLcdvzIlTVlUm+kuQD3f3b51p0lzHbdRe7bNMD21dXIbank1y34/drkzy+pLkcWt39+OLyqSRfy9YpjSe3TxctLp9a3gwPtXNtR/vuHnT3k939THf/Mclncvb0m+15garq+dmKwhe6+6uLYfvpPuy2TQ9yX12F2H4/ybGqekVV/Vm2nnS+Z8lzOlSq6s+r6qrt60n+KslD2dqOtywWuyXJ15czw0PvXNvxniTvWrza83VJfrN9Go9ze9bzhW/L1r6abG3Pm6vqBVX1imy9oOd7l3p+q66qKslnkzzS3Z/ccZP9dI/OtU0Pcl+94mCnfPG6++mqel+Sv0/yvCR3dvfDS57WYXN1kq9t7S+5IsnfdvffVdX3k9xdVe9J8oskb1/iHA+FqvpikjcmeUlVnU7ykSQfz+7b8d4kN2brxRG/T/LuSz7hFXeO7fnGqrohW6fdHk3y3iTp7oer6u4kP87Wq0Nv7e5nljHvFfeGJO9M8qOqenAx9uHYT/fjXNv0HQe1r/oEKQAYtgqnkQFgrYktAAwTWwAYJrYAMExsAWCY2ALAMLEFgGFiCwDD/j+o8Sx5qwnojgAAAABJRU5ErkJggg==%0A">
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>As you can see it in observation, the dimension of observation is changed from 2D to 1D. Using this observation, we will make some kind of neural network to help agent to notice the observation. Let's check the real-time video of random movement.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">gym.wrappers</span> <span class="kn">import</span> <span class="n">Monitor</span>

<span class="c1"># Monitor is a gym wrapper, which helps easy rendering of videos of the wrapped environment.</span>
<span class="k">def</span> <span class="nf">wrap_env</span><span class="p">(</span><span class="n">env</span><span class="p">):</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">Monitor</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="s1">'./video'</span><span class="p">,</span> <span class="n">force</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">env</span>

<span class="k">def</span> <span class="nf">gen_wrapped_env</span><span class="p">(</span><span class="n">env_name</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">wrap_env</span><span class="p">(</span><span class="n">FlatObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">env_name</span><span class="p">)))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>Currently, OpenAI Gym offers several utils to help understanding the training progress. Monitor is one of that tool to log the history data. If we set the rendering option to <code>rgb_array</code>, the video data will be stored in specific path. (Maybe it requires some additional apps such as ffmpeg)</p>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Test-with-Random-Policy">
<a class="anchor" href="#Test-with-Random-Policy" aria-hidden="true"><span class="octicon octicon-link"></span></a>Test with Random Policy<a class="anchor-link" href="#Test-with-Random-Policy"> </a>
</h2>
</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">RandPolicy</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">action_space</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span> <span class="o">=</span> <span class="n">action_space</span>
        
    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">unused_args</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">sample</span><span class="p">(),</span> <span class="kc">None</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>At first, we want check the operation of environment-agent interaction. To do this, Random Policy that generates the "random action" is defined. This policy just generates random action from pre-defined action space. And then run it.</p>
<blockquote>
<p>Note that <code>pytorch_policy</code> flag is set to <code>False</code> as a default. But to implement the policy gradient, the gradient calculation is required, and pytorch will be used.</p>
</blockquote>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">def</span> <span class="nf">log_policy_rollout</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">env_name</span><span class="p">,</span> <span class="n">pytorch_policy</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
    <span class="c1"># Create environment with flat observation</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">gen_wrapped_env</span><span class="p">(</span><span class="n">env_name</span><span class="p">)</span>

    <span class="c1"># Initialize environment</span>
    <span class="n">observation</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

    <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
    <span class="n">episode_reward</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="n">episode_length</span> <span class="o">=</span> <span class="mi">0</span>

    <span class="c1"># Run until done == True</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="n">done</span><span class="p">:</span>
      <span class="c1"># Take a step</span>
        <span class="k">if</span> <span class="n">pytorch_policy</span><span class="p">:</span> 
            <span class="n">observation</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">observation</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">action</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">observation</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
        <span class="n">observation</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

        <span class="n">episode_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        <span class="n">episode_length</span> <span class="o">+=</span> <span class="mi">1</span>

    <span class="nb">print</span><span class="p">(</span><span class="s1">'Total reward:'</span><span class="p">,</span> <span class="n">episode_reward</span><span class="p">)</span>
    <span class="nb">print</span><span class="p">(</span><span class="s1">'Total length:'</span><span class="p">,</span> <span class="n">episode_length</span><span class="p">)</span>

    <span class="n">env</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>
    
    <span class="n">show_video</span><span class="p">()</span>

<span class="c1"># Test that the logging function is working</span>
<span class="n">test_env_name</span> <span class="o">=</span> <span class="s1">'MiniGrid-Empty-8x8-v0'</span>
<span class="n">rand_policy</span> <span class="o">=</span> <span class="n">RandPolicy</span><span class="p">(</span><span class="n">FlatObsWrapper</span><span class="p">(</span><span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">test_env_name</span><span class="p">))</span><span class="o">.</span><span class="n">action_space</span><span class="p">)</span>
<span class="n">log_policy_rollout</span><span class="p">(</span><span class="n">rand_policy</span><span class="p">,</span> <span class="n">test_env_name</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total reward: 0
Total length: 50
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<video alt="test" autoplay="" loop="" controls="" style="height: 400px;">
                <source src="data:video/mp4;base64,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" type="video/mp4"></source>
             </video>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>That's the agent work with Random Policy. We found out that Random Policy is not optimal policy since the agent (the red one) cannot reach the goal.(or maybe it'll reach the goal after infinite times go on...)  So to reach the goal, it requires more intelligent policy. In natural sense of mind, it needs,</p>
<ul>
<li>Remember the previous trajectory</li>
<li>When it goes to unknown cell, based on the experience with memory, use it to find the way to goal</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Implement-Rollout-Buffer">
<a class="anchor" href="#Implement-Rollout-Buffer" aria-hidden="true"><span class="octicon octicon-link"></span></a>Implement Rollout Buffer<a class="anchor-link" href="#Implement-Rollout-Buffer"> </a>
</h2>
<p>Before implementing Policy Gradient, it requires to implement memory object to store the previous trajectory or information offered from environment. Sometimes, it is called "Replay Buffer" or "Rollout Buffer", but in this page, RolloutBuffer will be used for expression. To implement Rollout Buffer, we need to consider such that,</p>
<ul>
<li>how many trajectories stored in buffer?</li>
<li>how to add trajectory into the buffer?</li>
<li>(In view of Reinforcement Learning) how to calculate the future reward based on previous reward</li>
<li>(+) how to sample the trajectory efficiently?</li>
</ul>
<p>So this is RolloutBuffer implementation!</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">torch.utils.data.sampler</span> <span class="kn">import</span> <span class="n">BatchSampler</span><span class="p">,</span> <span class="n">SubsetRandomSampler</span>

<span class="k">class</span> <span class="nc">RolloutBuffer</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rollout_size</span><span class="p">,</span> <span class="n">obs_size</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span> <span class="o">=</span> <span class="n">rollout_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs_size</span> <span class="o">=</span> <span class="n">obs_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        
    <span class="k">def</span> <span class="nf">insert</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">step</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">obs</span><span class="p">):</span>    
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">done</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">log_prob</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">reward</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">step</span><span class="p">]</span><span class="o">.</span><span class="n">copy_</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">reset</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">returns</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="c1"># Assuming Discrete Action Space</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actions</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs_size</span><span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">compute_returns</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">gamma</span><span class="p">):</span>
        <span class="c1"># Compute Returns until the last finished episode</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">last_done</span> <span class="o">=</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">done</span> <span class="o">==</span> <span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">nonzero</span><span class="p">()</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>  
        <span class="bp">self</span><span class="o">.</span><span class="n">returns</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">last_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="mf">0.</span>

        <span class="c1"># Accumulate discounted returns</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_done</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">returns</span><span class="p">[</span><span class="n">step</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">returns</span><span class="p">[</span><span class="n">step</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span> <span class="o">*</span> \
                <span class="n">gamma</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="bp">self</span><span class="o">.</span><span class="n">done</span><span class="p">[</span><span class="n">step</span><span class="p">])</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">rewards</span><span class="p">[</span><span class="n">step</span><span class="p">]</span>
        
    <span class="k">def</span> <span class="nf">batch_sampler</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">get_old_log_probs</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
        <span class="n">sampler</span> <span class="o">=</span> <span class="n">BatchSampler</span><span class="p">(</span>
            <span class="n">SubsetRandomSampler</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">last_done</span><span class="p">)),</span>
            <span class="n">batch_size</span><span class="p">,</span>
            <span class="n">drop_last</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
        <span class="k">for</span> <span class="n">indices</span> <span class="ow">in</span> <span class="n">sampler</span><span class="p">:</span>
            <span class="k">if</span> <span class="n">get_old_log_probs</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">returns</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">log_probs</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="k">yield</span> <span class="bp">self</span><span class="o">.</span><span class="n">actions</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">returns</span><span class="p">[</span><span class="n">indices</span><span class="p">],</span> <span class="bp">self</span><span class="o">.</span><span class="n">obs</span><span class="p">[</span><span class="n">indices</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>There are couple of things to notice that,</p>
<ul>
<li>All information stored in RolloutBuffer should get the type of <code>torch.Tensor</code>
</li>
<li>In this case, returns will be used for minimizing the loss. So returns object should set the <code>requires_grad</code> to <code>True</code>
</li>
<li>It is inefficient to use all information to train the policy. To handle it, it requires something special sampling strategy. In this code, <code>BatchSample</code> is used.</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Construct-Policy-Network">
<a class="anchor" href="#Construct-Policy-Network" aria-hidden="true"><span class="octicon octicon-link"></span></a>Construct Policy Network<a class="anchor-link" href="#Construct-Policy-Network"> </a>
</h2>
<p>Now that we can store rollouts we need a policy to collect them. In the following you will complete the provided base code for the policy class. The policy is instantiated as a small neural network with simple fully-connected layers, the <code>ActorNetwork</code>. The role of policy is sort of strategy that generates the action. (Actually, it is just the probability to generate the action).
 And Of course, the important work through <code>ActorNetwork</code> is to update policy per each iteration. With pytorch, we need to define,</p>
<ul>
<li>What optimizer should we use?</li>
<li>How can we define the loss function?</li>
</ul>
<p>At first, Let's look gradient function used in policy gradient,</p>
<p>
$$ \nabla J(\theta) = \mathbb{E}_{\pi}\big[ \nabla_{\theta} \log \pi_{\theta}(a, s) \; V_t(s) \big] $$
</p>
<p>Here, $\theta$ are the parameters of the policy network $\pi_{\theta}$ and $V_t(s)$ is the observed future discounted reward from state $s$ onwards which should be <strong>maximized</strong> (we need to focus on this keyword, since the purpose of neural network training is to <strong>minimize</strong> the loss, not <strong>maximize</strong>). So anyway we need the calculate the gradient of $\log \pi_{\theta}(a, s)$ and calculate its mean.</p>
<p>And Plus, there are some approaches to enhance the exploration. If we can consider the <strong>entropy loss</strong> to handle the overall loss, it takes diverse action. At that case gradient fuction will be,</p>
<p>
$$ \nabla J(\theta) = \mathbb{E}_{\pi}\big[ \nabla_{\theta} \log \pi_{\theta}(a, s) \; V_t(s) \big] + \nabla_{\theta}\mathcal{H}\big[\pi_\theta(a, s)\big]$$
</p>
<p>And here is the implementation of Actor Network (and it's quite simple!)</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn</span> <span class="k">as</span> <span class="nn">nn</span>

<span class="k">class</span> <span class="nc">ActorNetwork</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">num_actions</span> <span class="o">=</span> <span class="n">num_actions</span>
        
        <span class="bp">self</span><span class="o">.</span><span class="n">fc</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Sequential</span><span class="p">(</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Tanh</span><span class="p">(),</span>
            <span class="n">nn</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">hidden_dim</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">)</span>
        <span class="p">)</span>
        
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">fc</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">x</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And Below is the implementation of Policy. We select the Adam Optimizer</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">torch.optim</span> <span class="k">as</span> <span class="nn">optim</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">from</span> <span class="nn">torch.distributions.categorical</span> <span class="kn">import</span> <span class="n">Categorical</span>
<span class="kn">from</span> <span class="nn">utils.utils</span> <span class="kn">import</span> <span class="n">count_model_params</span>

<span class="k">class</span> <span class="nc">Policy</span><span class="p">():</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">,</span> <span class="n">learning_rate</span><span class="p">,</span>
                 <span class="n">batch_size</span><span class="p">,</span> <span class="n">policy_epochs</span><span class="p">,</span> <span class="n">entropy_coef</span><span class="o">=</span><span class="mf">0.001</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">actor</span> <span class="o">=</span> <span class="n">ActorNetwork</span><span class="p">(</span><span class="n">num_inputs</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="n">hidden_dim</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">optim</span><span class="o">.</span><span class="n">Adam</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">learning_rate</span><span class="p">)</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">policy_epochs</span> <span class="o">=</span> <span class="n">policy_epochs</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">=</span> <span class="n">entropy_coef</span>

    <span class="k">def</span> <span class="nf">act</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="c1"># To generate the probability of action, we assume its state has categorical distribution.</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">action</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">sample</span><span class="p">()</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span>
    
    <span class="k">def</span> <span class="nf">evaluate_actions</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">state</span><span class="p">,</span> <span class="n">action</span><span class="p">):</span>
        <span class="n">logits</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="n">dist</span> <span class="o">=</span> <span class="n">Categorical</span><span class="p">(</span><span class="n">logits</span><span class="o">=</span><span class="n">logits</span><span class="p">)</span>
        <span class="n">log_prob</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">action</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">))</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="n">entropy</span> <span class="o">=</span> <span class="n">dist</span><span class="o">.</span><span class="n">entropy</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">log_prob</span><span class="p">,</span> <span class="n">entropy</span>
    
    <span class="k">def</span> <span class="nf">update</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">rollouts</span><span class="p">):</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">policy_epochs</span><span class="p">):</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">rollouts</span><span class="o">.</span><span class="n">batch_sampler</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span><span class="p">)</span>
            
            <span class="k">for</span> <span class="n">sample</span> <span class="ow">in</span> <span class="n">data</span><span class="p">:</span>
                <span class="n">actions_batch</span><span class="p">,</span> <span class="n">returns_batch</span><span class="p">,</span> <span class="n">obs_batch</span> <span class="o">=</span> <span class="n">sample</span>
    
                <span class="n">log_probs_batch</span><span class="p">,</span> <span class="n">entropy_batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">evaluate_actions</span><span class="p">(</span><span class="n">obs_batch</span><span class="p">,</span> <span class="n">actions_batch</span><span class="p">)</span>
    
                <span class="c1"># Compute the mean loss for the policy update using </span>
                <span class="c1"># action log-probabilities and policy returns</span>
                <span class="n">policy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="p">(</span><span class="n">log_probs_batch</span> <span class="o">*</span> <span class="n">returns_batch</span><span class="p">)</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                <span class="c1"># Compute the mean entropy for the policy update </span>
                <span class="n">entropy_loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">entropy_batch</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
                
                <span class="n">loss</span> <span class="o">=</span> <span class="n">policy_loss</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">entropy_coef</span> <span class="o">*</span> <span class="n">entropy_loss</span>
                
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">(</span><span class="n">retain_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                
    <span class="nd">@property</span>
    <span class="k">def</span> <span class="nf">num_params</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">count_model_params</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">actor</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">IPython.display</span> <span class="kn">import</span> <span class="n">clear_output</span>
<span class="kn">from</span> <span class="nn">utils.utils</span> <span class="kn">import</span> <span class="n">AverageMeter</span><span class="p">,</span> <span class="n">plot_learning_curve</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="k">def</span> <span class="nf">train</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">rollouts</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">params</span><span class="p">,</span> <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">):</span>
    <span class="c1"># SETTING SEED: it is good practice to set seeds when running experiments to keep results comparable</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
    <span class="n">env</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">rollout_time</span><span class="p">,</span> <span class="n">update_time</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(),</span> <span class="n">AverageMeter</span><span class="p">()</span>  <span class="c1"># Loggers</span>
    <span class="n">rewards</span><span class="p">,</span> <span class="n">success_rate</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>

    <span class="nb">print</span><span class="p">(</span><span class="s2">"Training model with </span><span class="si">{}</span><span class="s2"> parameters..."</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">policy</span><span class="o">.</span><span class="n">num_params</span><span class="p">))</span>

    <span class="c1"># Training Loop</span>
    <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">num_updates</span><span class="p">):</span>
        <span class="c1">## Initialization</span>
        <span class="n">avg_eps_reward</span><span class="p">,</span> <span class="n">avg_success_rate</span> <span class="o">=</span> <span class="n">AverageMeter</span><span class="p">(),</span> <span class="n">AverageMeter</span><span class="p">()</span>
        <span class="n">done</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">prev_obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
        <span class="n">prev_obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">prev_obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
        <span class="n">eps_reward</span> <span class="o">=</span> <span class="mf">0.</span>
        <span class="n">start_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        
        <span class="c1">## Collect rollouts</span>
        <span class="k">for</span> <span class="n">step</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">rollouts</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">):</span>
            <span class="k">if</span> <span class="n">done</span><span class="p">:</span>
                <span class="c1"># Store episode statistics</span>
                <span class="n">avg_eps_reward</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">eps_reward</span><span class="p">)</span>
                <span class="k">if</span> <span class="s1">'success'</span> <span class="ow">in</span> <span class="n">info</span><span class="p">:</span> 
                    <span class="n">avg_success_rate</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="nb">int</span><span class="p">(</span><span class="n">info</span><span class="p">[</span><span class="s1">'success'</span><span class="p">]))</span>

                <span class="c1"># Reset Environment</span>
                <span class="n">obs</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
                <span class="n">obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
                <span class="n">eps_reward</span> <span class="o">=</span> <span class="mf">0.</span>
            <span class="k">else</span><span class="p">:</span>
                <span class="n">obs</span> <span class="o">=</span> <span class="n">prev_obs</span>

            <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span> <span class="o">=</span> <span class="n">policy</span><span class="o">.</span><span class="n">act</span><span class="p">(</span><span class="n">obs</span><span class="p">)</span>
            <span class="n">obs</span><span class="p">,</span> <span class="n">reward</span><span class="p">,</span> <span class="n">done</span><span class="p">,</span> <span class="n">info</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">action</span><span class="p">)</span>

            <span class="n">rollouts</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">step</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">done</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> <span class="n">action</span><span class="p">,</span> <span class="n">log_prob</span><span class="p">,</span> 
                            <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">reward</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span> 
                            <span class="n">prev_obs</span><span class="p">)</span>
            
            <span class="n">prev_obs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="n">obs</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span>
            <span class="n">eps_reward</span> <span class="o">+=</span> <span class="n">reward</span>
        
        <span class="c1"># Use the rollout buffer's function to compute the returns for all stored rollout steps. (requires just 1 line)</span>
        <span class="n">rollouts</span><span class="o">.</span><span class="n">compute_returns</span><span class="p">(</span><span class="n">params</span><span class="p">[</span><span class="s1">'discount'</span><span class="p">])</span>
        
        <span class="n">rollout_done_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>

        
        <span class="c1"># Call the policy's update function using the collected rollouts        </span>
        <span class="n">policy</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">rollouts</span><span class="p">)</span>

        <span class="n">update_done_time</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
        <span class="n">rollouts</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>

        <span class="c1">## log metrics</span>
        <span class="n">rewards</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_eps_reward</span><span class="o">.</span><span class="n">avg</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">avg_success_rate</span><span class="o">.</span><span class="n">count</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">success_rate</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">avg_success_rate</span><span class="o">.</span><span class="n">avg</span><span class="p">)</span>
        <span class="n">rollout_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">rollout_done_time</span> <span class="o">-</span> <span class="n">start_time</span><span class="p">)</span>
        <span class="n">update_time</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">update_done_time</span> <span class="o">-</span> <span class="n">rollout_done_time</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">'it </span><span class="si">{}</span><span class="s1">: avgR: </span><span class="si">{:.3f}</span><span class="s1"> -- rollout_time: </span><span class="si">{:.3f}</span><span class="s1">sec -- update_time: </span><span class="si">{:.3f}</span><span class="s1">sec'</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">j</span><span class="p">,</span> 
                                                                                                <span class="n">avg_eps_reward</span><span class="o">.</span><span class="n">avg</span><span class="p">,</span> 
                                                                                                <span class="n">rollout_time</span><span class="o">.</span><span class="n">avg</span><span class="p">,</span>
                                                                                                <span class="n">update_time</span><span class="o">.</span><span class="n">avg</span><span class="p">))</span>
        <span class="k">if</span> <span class="n">j</span> <span class="o">%</span> <span class="n">params</span><span class="o">.</span><span class="n">plotting_iters</span> <span class="o">==</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">j</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
            <span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">success_rate</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">num_updates</span><span class="p">)</span>
            <span class="n">log_policy_rollout</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">env_name</span><span class="p">,</span> <span class="n">pytorch_policy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">clear_output</span><span class="p">()</span>   <span class="c1"># this removes all training outputs to keep the notebook clean, DON'T REMOVE THIS LINE!</span>
    <span class="k">return</span> <span class="n">rewards</span><span class="p">,</span> <span class="n">success_rate</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">utils.utils</span> <span class="kn">import</span> <span class="n">ParamDict</span>
<span class="kn">import</span> <span class="nn">copy</span>

<span class="k">def</span> <span class="nf">instantiate</span><span class="p">(</span><span class="n">params_in</span><span class="p">,</span> <span class="n">nonwrapped_env</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
    <span class="n">params</span> <span class="o">=</span> <span class="n">copy</span><span class="o">.</span><span class="n">deepcopy</span><span class="p">(</span><span class="n">params_in</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">nonwrapped_env</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">nonwrapped_env</span> <span class="o">=</span> <span class="n">gym</span><span class="o">.</span><span class="n">make</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">env_name</span><span class="p">)</span>

    <span class="n">env</span> <span class="o">=</span> <span class="kc">None</span>
    <span class="n">env</span> <span class="o">=</span> <span class="n">FlatObsWrapper</span><span class="p">(</span><span class="n">nonwrapped_env</span><span class="p">)</span>    
    <span class="n">obs_size</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">observation_space</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">num_actions</span> <span class="o">=</span> <span class="n">env</span><span class="o">.</span><span class="n">action_space</span><span class="o">.</span><span class="n">n</span>

    <span class="n">rollouts</span> <span class="o">=</span> <span class="n">RolloutBuffer</span><span class="p">(</span><span class="n">params</span><span class="o">.</span><span class="n">rollout_size</span><span class="p">,</span> <span class="n">obs_size</span><span class="p">)</span>
    <span class="n">policy_class</span> <span class="o">=</span> <span class="n">params</span><span class="o">.</span><span class="n">policy_params</span><span class="o">.</span><span class="n">pop</span><span class="p">(</span><span class="s1">'policy_class'</span><span class="p">)</span>
    
    <span class="n">policy</span> <span class="o">=</span> <span class="n">policy_class</span><span class="p">(</span><span class="n">obs_size</span><span class="p">,</span> <span class="n">num_actions</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="o">.</span><span class="n">policy_params</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">env</span><span class="p">,</span> <span class="n">rollouts</span><span class="p">,</span> <span class="n">policy</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">policy_params</span> <span class="o">=</span> <span class="n">ParamDict</span><span class="p">(</span>
    <span class="n">policy_class</span> <span class="o">=</span> <span class="n">Policy</span><span class="p">,</span>    <span class="c1"># Policy class to use (replaced later)     </span>
    <span class="n">hidden_dim</span> <span class="o">=</span> <span class="mi">32</span><span class="p">,</span>          <span class="c1"># dimension of the hidden state in actor network</span>
    <span class="n">learning_rate</span> <span class="o">=</span> <span class="mf">1e-3</span><span class="p">,</span>     <span class="c1"># learning rate of policy update</span>
    <span class="n">batch_size</span> <span class="o">=</span> <span class="mi">1024</span><span class="p">,</span>        <span class="c1"># batch size for policy update</span>
    <span class="n">policy_epochs</span> <span class="o">=</span> <span class="mi">4</span><span class="p">,</span>        <span class="c1"># number of epochs per policy update</span>
    <span class="n">entropy_coef</span> <span class="o">=</span> <span class="mf">0.001</span><span class="p">,</span>     <span class="c1"># hyperparameter to vary the contribution of entropy loss</span>
<span class="p">)</span>
<span class="n">params</span> <span class="o">=</span> <span class="n">ParamDict</span><span class="p">(</span>
    <span class="n">policy_params</span> <span class="o">=</span> <span class="n">policy_params</span><span class="p">,</span>
    <span class="n">rollout_size</span> <span class="o">=</span> <span class="mi">2050</span><span class="p">,</span>      <span class="c1"># number of collected rollout steps per policy update</span>
    <span class="n">num_updates</span> <span class="o">=</span> <span class="mi">50</span><span class="p">,</span>         <span class="c1"># number of training policy iterations</span>
    <span class="n">discount</span> <span class="o">=</span> <span class="mf">0.99</span><span class="p">,</span>          <span class="c1"># discount factor</span>
    <span class="n">plotting_iters</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>      <span class="c1"># interval for logging graphs and policy rollouts</span>
    <span class="n">env_name</span> <span class="o">=</span> <span class="s1">'MiniGrid-Empty-5x5-v0'</span><span class="p">,</span>  <span class="c1"># we are using a tiny environment here for testing</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">env</span><span class="p">,</span> <span class="n">rollouts</span><span class="p">,</span> <span class="n">policy</span> <span class="o">=</span> <span class="n">instantiate</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
<span class="n">rewards</span><span class="p">,</span> <span class="n">success_rate</span> <span class="o">=</span> <span class="n">train</span><span class="p">(</span><span class="n">env</span><span class="p">,</span> <span class="n">rollouts</span><span class="p">,</span> <span class="n">policy</span><span class="p">,</span> <span class="n">params</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">"Training completed!"</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Training completed!
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">plot_learning_curve</span><span class="p">(</span><span class="n">rewards</span><span class="p">,</span> <span class="n">success_rate</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">num_updates</span><span class="p">)</span>
<span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>
    <span class="n">log_policy_rollout</span><span class="p">(</span><span class="n">policy</span><span class="p">,</span> <span class="n">params</span><span class="o">.</span><span class="n">env_name</span><span class="p">,</span> <span class="n">pytorch_policy</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_png output_subarea ">
<img src="data:image/png;base64,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%0A">
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total reward: 0.874
Total length: 7
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<video alt="test" autoplay="" loop="" controls="" style="height: 400px;">
                <source src="data:video/mp4;base64,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" type="video/mp4"></source>
             </video>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total reward: 0.91
Total length: 5
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<video alt="test" autoplay="" loop="" controls="" style="height: 400px;">
                <source src="data:video/mp4;base64,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" type="video/mp4"></source>
             </video>
</div>

</div>

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>Total reward: 0.874
Total length: 7
</pre>
</div>
</div>

<div class="output_area">


<div class="output_html rendered_html output_subarea ">
<video alt="test" autoplay="" loop="" controls="" style="height: 400px;">
                <source src="data:video/mp4;base64,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" type="video/mp4"></source>
             </video>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/pytorch/reinforcement_learning/2020/08/06/03-Policy-Gradient-With-Gym-MiniGrid.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/goodboychan" title="goodboychan"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chanseokk" title="chanseokk"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
