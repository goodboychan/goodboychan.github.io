<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Dealing with Text Data | Chan`s Jupyter</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Dealing with Text Data" />
<meta name="author" content="Chanseok Kang" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Finally, in this chapter, you will work with unstructured text data, understanding ways in which you can engineer columnar features out of a text corpus. You will compare how different approaches may impact how much context is being extracted from a text, and how to balance the need for context, without too many features being created. This is the Summary of lecture “Feature Engineering for Machine Learning in Python”, via datacamp." />
<meta property="og:description" content="Finally, in this chapter, you will work with unstructured text data, understanding ways in which you can engineer columnar features out of a text corpus. You will compare how different approaches may impact how much context is being extracted from a text, and how to balance the need for context, without too many features being created. This is the Summary of lecture “Feature Engineering for Machine Learning in Python”, via datacamp." />
<link rel="canonical" href="https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/12/04-Dealing-with-Text-Data.html" />
<meta property="og:url" content="https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/12/04-Dealing-with-Text-Data.html" />
<meta property="og:site_name" content="Chan`s Jupyter" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-07-12T00:00:00-05:00" />
<script type="application/ld+json">
{"description":"Finally, in this chapter, you will work with unstructured text data, understanding ways in which you can engineer columnar features out of a text corpus. You will compare how different approaches may impact how much context is being extracted from a text, and how to balance the need for context, without too many features being created. This is the Summary of lecture “Feature Engineering for Machine Learning in Python”, via datacamp.","url":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/12/04-Dealing-with-Text-Data.html","@type":"BlogPosting","headline":"Dealing with Text Data","dateModified":"2020-07-12T00:00:00-05:00","datePublished":"2020-07-12T00:00:00-05:00","author":{"@type":"Person","name":"Chanseok Kang"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://goodboychan.github.io/python/datacamp/machine_learning/2020/07/12/04-Dealing-with-Text-Data.html"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://goodboychan.github.io/feed.xml" title="Chan`s Jupyter" /><!-- the google_analytics_id gets auto inserted from the config file -->



<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-33905785-1"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-33905785-1');
</script>


<link rel="shortcut icon" type="image/x-icon" href="/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.css" integrity="sha512-h7nl+xz8wgDlNM4NqKEM4F1NkIRS17M9+uJwIGwuo8vGqIl4BhuCKdxjWEINm+xyrUjNCnK5dCrhM0sj+wTIXw==" crossorigin="anonymous" />
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/katex.min.js" integrity="sha512-/CMIhXiDA3m2c9kzRyd97MTb3MC6OVnx4TElQ7fkkoRghwDf6gi41gaT1PwF270W6+J60uTmwgeRpNpJdRV6sg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.12.0/contrib/auto-render.min.js" integrity="sha512-Do7uJAaHZm5OLrIv/yN4w0iG1dbu01kzdMNnFfu/mAqgUk6Nniv2JYHcwH+cNwjqgLcqcuBBk+JRvprLVI8azg==" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha512-0doc9hKxR3PYwso42RD1p5ySZpzzuDiOwMrdCEh2WdJZCjcmFKc/wEnL+z8fBQrnHoiNWbo+3fiGkOYXBdQp4A==" crossorigin="anonymous"></script>
    <script>
    document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
        delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
        ]}
        );
    });
    </script>


<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>

<script data-ad-client="ca-pub-6747875619665490" async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js"></script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Chan`s Jupyter</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/about/">About Me</a><a class="page-link" href="/book/">Book</a><a class="page-link" href="/search/">Search</a><a class="page-link" href="/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Dealing with Text Data</h1><p class="page-description">Finally, in this chapter, you will work with unstructured text data, understanding ways in which you can engineer columnar features out of a text corpus. You will compare how different approaches may impact how much context is being extracted from a text, and how to balance the need for context, without too many features being created. This is the Summary of lecture "Feature Engineering for Machine Learning in Python", via datacamp.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-07-12T00:00:00-05:00" itemprop="datePublished">
        Jul 12, 2020
      </time>• 
          <span itemprop="author" itemscope itemtype="http://schema.org/Person">
            <span class="p-author h-card" itemprop="name">Chanseok Kang</span></span>
       • <span class="read-time" title="Estimated read time">
    
    
      11 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/categories/#Python">Python</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Datacamp">Datacamp</a>
        &nbsp;
      
        <a class="category-tags-link" href="/categories/#Machine_Learning">Machine_Learning</a>
        
      
      </p>
    

    
      
        <div class="pb-5 d-flex flex-wrap flex-justify-end">
          <div class="px-2">

    <a href="https://github.com/goodboychan/goodboychan.github.io/tree/main/_notebooks/2020-07-12-04-Dealing-with-Text-Data.ipynb" role="button" target="_blank">
<img class="notebook-badge-image" src="/assets/badges/github.svg" alt="View On GitHub">
    </a>
</div>

          <div class="px-2">
    <a href="https://mybinder.org/v2/gh/goodboychan/goodboychan.github.io/main?filepath=_notebooks%2F2020-07-12-04-Dealing-with-Text-Data.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/binder.svg" alt="Open In Binder"/>
    </a>
</div>

          <div class="px-2">
    <a href="https://colab.research.google.com/github/goodboychan/goodboychan.github.io/blob/main/_notebooks/2020-07-12-04-Dealing-with-Text-Data.ipynb" target="_blank">
        <img class="notebook-badge-image" src="/assets/badges/colab.svg" alt="Open In Colab"/>
    </a>
</div>

        </div>
      </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#Encoding-text">Encoding text </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Cleaning-up-your-text">Cleaning up your text </a></li>
<li class="toc-entry toc-h3"><a href="#High-level-text-features">High level text features </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Word-counts">Word counts </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Counting-words-(I)">Counting words (I) </a></li>
<li class="toc-entry toc-h3"><a href="#Counting-words-(II)">Counting words (II) </a></li>
<li class="toc-entry toc-h3"><a href="#Limiting-your-features">Limiting your features </a></li>
<li class="toc-entry toc-h3"><a href="#Text-to-DataFrame">Text to DataFrame </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#Term-frequency-inverse-document-frequency">Term frequency-inverse document frequency </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Tf-idf">Tf-idf </a></li>
<li class="toc-entry toc-h3"><a href="#Inspecting-Tf-idf-values">Inspecting Tf-idf values </a></li>
<li class="toc-entry toc-h3"><a href="#Transforming-unseen-data">Transforming unseen data </a></li>
</ul>
</li>
<li class="toc-entry toc-h2"><a href="#N-grams">N-grams </a>
<ul>
<li class="toc-entry toc-h3"><a href="#Using-longer-n-grams">Using longer n-grams </a></li>
<li class="toc-entry toc-h3"><a href="#Finding-the-most-common-words">Finding the most common words </a></li>
</ul>
</li>
</ul><!--
#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: _notebooks/2020-07-12-04-Dealing-with-Text-Data.ipynb
-->

<div class="container" id="notebook-container">
        
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s1">'figure.figsize'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Encoding-text">
<a class="anchor" href="#Encoding-text" aria-hidden="true"><span class="octicon octicon-link"></span></a>Encoding text<a class="anchor-link" href="#Encoding-text"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Cleaning-up-your-text">
<a class="anchor" href="#Cleaning-up-your-text" aria-hidden="true"><span class="octicon octicon-link"></span></a>Cleaning up your text<a class="anchor-link" href="#Cleaning-up-your-text"> </a>
</h3>
<p>Unstructured text data cannot be directly used in most analyses. Multiple steps need to be taken to go from a long free form string to a set of numeric columns in the right format that can be ingested by a machine learning model. The first step of this process is to standardize the data and eliminate any characters that could cause problems later on in your analytic pipeline.</p>
<p>In this chapter you will be working with a new dataset containing the inaugural speeches of the presidents of the United States loaded as <code>speech_df</code>, with the speeches stored in the <code>text</code> column.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">speech_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">'./dataset/inaugural_speeches.csv'</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>0    Fellow-Citizens of the Senate and of the House...
1    Fellow Citizens:  I AM again called upon by th...
2    WHEN it was first perceived, in early times, t...
3    Friends and Fellow-Citizens:  CALLED upon to u...
4    PROCEEDING, fellow-citizens, to that qualifica...
Name: text, dtype: object</pre>
</div>

</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'text'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="s1">'[^a-zA-Z]'</span><span class="p">,</span> <span class="s1">' '</span><span class="p">)</span>

<span class="c1"># Change to lower case</span>
<span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span> <span class="o">=</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">lower</span><span class="p">()</span>

<span class="c1"># Print the first 5 rows of text_clean column</span>
<span class="nb">print</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>0    fellow citizens of the senate and of the house...
1    fellow citizens   i am again called upon by th...
2    when it was first perceived  in early times  t...
3    friends and fellow citizens   called upon to u...
4    proceeding  fellow citizens  to that qualifica...
Name: text_clean, dtype: object
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="High-level-text-features">
<a class="anchor" href="#High-level-text-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>High level text features<a class="anchor-link" href="#High-level-text-features"> </a>
</h3>
<p>Once the text has been cleaned and standardized you can begin creating features from the data. The most fundamental information you can calculate about free form text is its size, such as its length and number of words. In this exercise (and the rest of this chapter), you will focus on the cleaned/transformed text column (<code>text_clean</code>) you created in the last exercise.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'char_cnt'</span><span class="p">]</span> <span class="o">=</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>

<span class="c1"># Count the number of words in each text</span>
<span class="n">speech_df</span><span class="p">[</span><span class="s1">'word_cnt'</span><span class="p">]</span> <span class="o">=</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">]</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">split</span><span class="p">()</span><span class="o">.</span><span class="n">str</span><span class="o">.</span><span class="n">len</span><span class="p">()</span>

<span class="c1"># Find the average length of word</span>
<span class="n">speech_df</span><span class="p">[</span><span class="s1">'avg_word_length'</span><span class="p">]</span> <span class="o">=</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'char_cnt'</span><span class="p">]</span> <span class="o">/</span> <span class="n">speech_df</span><span class="p">[</span><span class="s1">'word_cnt'</span><span class="p">]</span>

<span class="c1"># Print the first 5 rows of these columns</span>
<span class="n">speech_df</span><span class="p">[[</span><span class="s1">'text_clean'</span><span class="p">,</span> <span class="s1">'char_cnt'</span><span class="p">,</span> <span class="s1">'word_cnt'</span><span class="p">,</span> <span class="s1">'avg_word_length'</span><span class="p">]]</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>text_clean</th>
      <th>char_cnt</th>
      <th>word_cnt</th>
      <th>avg_word_length</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>fellow citizens of the senate and of the house...</td>
      <td>8616</td>
      <td>1432</td>
      <td>6.016760</td>
    </tr>
    <tr>
      <th>1</th>
      <td>fellow citizens   i am again called upon by th...</td>
      <td>787</td>
      <td>135</td>
      <td>5.829630</td>
    </tr>
    <tr>
      <th>2</th>
      <td>when it was first perceived  in early times  t...</td>
      <td>13871</td>
      <td>2323</td>
      <td>5.971158</td>
    </tr>
    <tr>
      <th>3</th>
      <td>friends and fellow citizens   called upon to u...</td>
      <td>10144</td>
      <td>1736</td>
      <td>5.843318</td>
    </tr>
    <tr>
      <th>4</th>
      <td>proceeding  fellow citizens  to that qualifica...</td>
      <td>12902</td>
      <td>2169</td>
      <td>5.948363</td>
    </tr>
  </tbody>
</table>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Word-counts">
<a class="anchor" href="#Word-counts" aria-hidden="true"><span class="octicon octicon-link"></span></a>Word counts<a class="anchor-link" href="#Word-counts"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Counting-words-(I)">
<a class="anchor" href="#Counting-words-(I)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Counting words (I)<a class="anchor-link" href="#Counting-words-(I)"> </a>
</h3>
<p>Once high level information has been recorded you can begin creating features based on the actual content of each text. One way to do this is to approach it in a similar way to how you worked with categorical variables in the earlier lessons.</p>
<ul>
<li>For each unique word in the dataset a column is created.</li>
<li>For each entry, the number of times this word occurs is counted and the count value is entered into the respective column.</li>
</ul>
<p>These <code>"count"</code> columns can then be used to train machine learning models.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Instantiate CountVectorizer</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">()</span>

<span class="c1"># Fit the vectorizer</span>
<span class="n">cv</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Print feature names</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()[:</span><span class="mi">10</span><span class="p">])</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>['abandon', 'abandoned', 'abandonment', 'abate', 'abdicated', 'abeyance', 'abhorring', 'abide', 'abiding', 'abilities']
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Counting-words-(II)">
<a class="anchor" href="#Counting-words-(II)" aria-hidden="true"><span class="octicon octicon-link"></span></a>Counting words (II)<a class="anchor-link" href="#Counting-words-(II)"> </a>
</h3>
<p>Once the vectorizer has been fit to the data, it can be used to transform the text to an array representing the word counts. This array will have a row per block of text and a column for each of the features generated by the vectorizer that you observed in the last exercise.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cv_transformed</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Print the full array</span>
<span class="n">cv_array</span> <span class="o">=</span> <span class="n">cv_transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_array</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>[[0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 1 0 ... 0 0 0]
 ...
 [0 1 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]
 [0 0 0 ... 0 0 0]]
</pre>
</div>
</div>

</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">cv_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(58, 9043)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Limiting-your-features">
<a class="anchor" href="#Limiting-your-features" aria-hidden="true"><span class="octicon octicon-link"></span></a>Limiting your features<a class="anchor-link" href="#Limiting-your-features"> </a>
</h3>
<p>As you have seen, using the <code>CountVectorizer</code> with its default settings creates a feature for every single word in your corpus. This can create far too many features, often including ones that will provide very little analytical value.</p>
<p>For this purpose <code>CountVectorizer</code> has parameters that you can set to reduce the number of features:</p>
<ul>
<li>
<code>min_df</code> : Use only words that occur in more than this percentage of documents. This can be used to remove outlier words that will not generalize across texts.</li>
<li>
<code>max_df</code> : Use only words that occur in less than this percentage of documents. This is useful to eliminate very common words that occur in every corpus without adding value such as "and" or "the".</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">CountVectorizer</span>

<span class="c1"># Specify arguments to limit the number of features generated</span>
<span class="n">cv</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">min_df</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span> <span class="n">max_df</span><span class="o">=</span><span class="mf">0.8</span><span class="p">)</span>

<span class="c1"># Fit, transform, and convert into array</span>
<span class="n">cv_transformed</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>
<span class="n">cv_array</span> <span class="o">=</span> <span class="n">cv_transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">()</span>

<span class="c1"># Print the array shape</span>
<span class="nb">print</span><span class="p">(</span><span class="n">cv_array</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>(58, 818)
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Text-to-DataFrame">
<a class="anchor" href="#Text-to-DataFrame" aria-hidden="true"><span class="octicon octicon-link"></span></a>Text to DataFrame<a class="anchor-link" href="#Text-to-DataFrame"> </a>
</h3>
<p>Now that you have generated these count based features in an array you will need to reformat them so that they can be combined with the rest of the dataset. This can be achieved by converting the array into a pandas DataFrame, with the feature names you found earlier as the column names, and then concatenate it with the original DataFrame.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_array</span><span class="p">,</span> <span class="n">columns</span> <span class="o">=</span> <span class="n">cv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span><span class="o">.</span><span class="n">add_prefix</span><span class="p">(</span><span class="s1">'Counts_'</span><span class="p">)</span>

<span class="c1"># Add the new columns to the original DataFrame</span>
<span class="n">speech_df_new</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">speech_df</span><span class="p">,</span> <span class="n">cv_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">sort</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">speech_df_new</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Name</th>
      <th>Inaugural Address</th>
      <th>Date</th>
      <th>text</th>
      <th>text_clean</th>
      <th>char_cnt</th>
      <th>word_cnt</th>
      <th>avg_word_length</th>
      <th>Counts_abiding</th>
      <th>Counts_ability</th>
      <th>...</th>
      <th>Counts_women</th>
      <th>Counts_words</th>
      <th>Counts_work</th>
      <th>Counts_wrong</th>
      <th>Counts_year</th>
      <th>Counts_years</th>
      <th>Counts_yet</th>
      <th>Counts_you</th>
      <th>Counts_young</th>
      <th>Counts_your</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>George Washington</td>
      <td>First Inaugural Address</td>
      <td>Thursday, April 30, 1789</td>
      <td>Fellow-Citizens of the Senate and of the House...</td>
      <td>fellow citizens of the senate and of the house...</td>
      <td>8616</td>
      <td>1432</td>
      <td>6.016760</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>0</td>
      <td>5</td>
      <td>0</td>
      <td>9</td>
    </tr>
    <tr>
      <th>1</th>
      <td>George Washington</td>
      <td>Second Inaugural Address</td>
      <td>Monday, March 4, 1793</td>
      <td>Fellow Citizens:  I AM again called upon by th...</td>
      <td>fellow citizens   i am again called upon by th...</td>
      <td>787</td>
      <td>135</td>
      <td>5.829630</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>2</th>
      <td>John Adams</td>
      <td>Inaugural Address</td>
      <td>Saturday, March 4, 1797</td>
      <td>WHEN it was first perceived, in early times, t...</td>
      <td>when it was first perceived  in early times  t...</td>
      <td>13871</td>
      <td>2323</td>
      <td>5.971158</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>3</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Thomas Jefferson</td>
      <td>First Inaugural Address</td>
      <td>Wednesday, March 4, 1801</td>
      <td>Friends and Fellow-Citizens:  CALLED upon to u...</td>
      <td>friends and fellow citizens   called upon to u...</td>
      <td>10144</td>
      <td>1736</td>
      <td>5.843318</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>1</td>
      <td>2</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>7</td>
      <td>0</td>
      <td>7</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Thomas Jefferson</td>
      <td>Second Inaugural Address</td>
      <td>Monday, March 4, 1805</td>
      <td>PROCEEDING, fellow-citizens, to that qualifica...</td>
      <td>proceeding  fellow citizens  to that qualifica...</td>
      <td>12902</td>
      <td>2169</td>
      <td>5.948363</td>
      <td>0</td>
      <td>0</td>
      <td>...</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>0</td>
      <td>2</td>
      <td>2</td>
      <td>2</td>
      <td>4</td>
      <td>0</td>
      <td>4</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 826 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="Term-frequency-inverse-document-frequency">
<a class="anchor" href="#Term-frequency-inverse-document-frequency" aria-hidden="true"><span class="octicon octicon-link"></span></a>Term frequency-inverse document frequency<a class="anchor-link" href="#Term-frequency-inverse-document-frequency"> </a>
</h2>
<ul>
<li>TF-IDF<ul>
<li>Term Frequency - Inverse Document Frequency
$$ \text{TF-IDF} = \frac{\frac{\text{count of word occurances}}{\text{Total words in documents}}}{\log (\frac{\text{Number of docs word is in}}{\text{Total number of docs}})} $$</li>
<li>Measures of what proportion of the documents a word occurs in all documents</li>
</ul>
</li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Tf-idf">
<a class="anchor" href="#Tf-idf" aria-hidden="true"><span class="octicon octicon-link"></span></a>Tf-idf<a class="anchor-link" href="#Tf-idf"> </a>
</h3>
<p>While counts of occurrences of words can be useful to build models, words that occur many times may skew the results undesirably. To limit these common words from overpowering your model a form of normalization can be used. In this lesson you will be using Term frequency-inverse document frequency (Tf-idf) as was discussed in the video. Tf-idf has the effect of reducing the value of common words, while increasing the weight of words that do not occur in many documents.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.feature_extraction.text</span> <span class="kn">import</span> <span class="n">TfidfVectorizer</span>

<span class="c1"># Instantiate TfidfVectorizer</span>
<span class="n">tv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">'english'</span><span class="p">)</span>

<span class="c1"># Fit the vectorizer and transform the data</span>
<span class="n">tv_transformed</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Create a DataFrame with these features</span>
<span class="n">tv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">tv_transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span>
                     <span class="n">columns</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span><span class="o">.</span><span class="n">add_prefix</span><span class="p">(</span><span class="s1">'TFIDF_'</span><span class="p">)</span>
<span class="n">tv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TFIDF_action</th>
      <th>TFIDF_administration</th>
      <th>TFIDF_america</th>
      <th>TFIDF_american</th>
      <th>TFIDF_americans</th>
      <th>TFIDF_believe</th>
      <th>TFIDF_best</th>
      <th>TFIDF_better</th>
      <th>TFIDF_change</th>
      <th>TFIDF_citizens</th>
      <th>...</th>
      <th>TFIDF_things</th>
      <th>TFIDF_time</th>
      <th>TFIDF_today</th>
      <th>TFIDF_union</th>
      <th>TFIDF_united</th>
      <th>TFIDF_war</th>
      <th>TFIDF_way</th>
      <th>TFIDF_work</th>
      <th>TFIDF_world</th>
      <th>TFIDF_years</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.133415</td>
      <td>0.000000</td>
      <td>0.105388</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.229644</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.045929</td>
      <td>0.0</td>
      <td>0.136012</td>
      <td>0.203593</td>
      <td>0.000000</td>
      <td>0.060755</td>
      <td>0.000000</td>
      <td>0.045929</td>
      <td>0.052694</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000000</td>
      <td>0.261016</td>
      <td>0.266097</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.179712</td>
      <td>...</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.199157</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.092436</td>
      <td>0.157058</td>
      <td>0.073018</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.026112</td>
      <td>0.060460</td>
      <td>0.000000</td>
      <td>0.106072</td>
      <td>...</td>
      <td>0.032030</td>
      <td>0.021214</td>
      <td>0.0</td>
      <td>0.062823</td>
      <td>0.070529</td>
      <td>0.024339</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.063643</td>
      <td>0.073018</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.000000</td>
      <td>0.092693</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.090942</td>
      <td>0.117831</td>
      <td>0.045471</td>
      <td>0.053335</td>
      <td>0.223369</td>
      <td>...</td>
      <td>0.048179</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.094497</td>
      <td>0.000000</td>
      <td>0.036610</td>
      <td>0.000000</td>
      <td>0.039277</td>
      <td>0.095729</td>
      <td>0.000000</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.041334</td>
      <td>0.039761</td>
      <td>0.000000</td>
      <td>0.031408</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.067393</td>
      <td>0.039011</td>
      <td>0.091514</td>
      <td>0.273760</td>
      <td>...</td>
      <td>0.082667</td>
      <td>0.164256</td>
      <td>0.0</td>
      <td>0.121605</td>
      <td>0.030338</td>
      <td>0.094225</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.054752</td>
      <td>0.062817</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 100 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Inspecting-Tf-idf-values">
<a class="anchor" href="#Inspecting-Tf-idf-values" aria-hidden="true"><span class="octicon octicon-link"></span></a>Inspecting Tf-idf values<a class="anchor-link" href="#Inspecting-Tf-idf-values"> </a>
</h3>
<p>After creating Tf-idf features you will often want to understand what are the most highest scored words for each corpus. This can be achieved by isolating the row you want to examine and then sorting the the scores from high to low.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">sample_row</span> <span class="o">=</span> <span class="n">tv_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># Print the top 5 words of the sorted output</span>
<span class="nb">print</span><span class="p">(</span><span class="n">sample_row</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">())</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stdout output_text">
<pre>TFIDF_government    0.367430
TFIDF_public        0.333237
TFIDF_present       0.315182
TFIDF_duty          0.238637
TFIDF_citizens      0.229644
Name: 0, dtype: float64
</pre>
</div>
</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Transforming-unseen-data">
<a class="anchor" href="#Transforming-unseen-data" aria-hidden="true"><span class="octicon octicon-link"></span></a>Transforming unseen data<a class="anchor-link" href="#Transforming-unseen-data"> </a>
</h3>
<p>When creating vectors from text, any transformations that you perform before training a machine learning model, you also need to apply on the new unseen (test) data. To achieve this follow the same approach from the last chapter: fit the vectorizer only on the training data, and apply it to the test data.</p>
<p>For this exercise the <code>speech_df</code> DataFrame has been split in two:</p>
<ul>
<li>
<code>train_speech_df</code>: The training set consisting of the first 45 speeches.</li>
<li>
<code>test_speech_df</code>: The test set consisting of the remaining speeches.</li>
</ul>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">train_speech_df</span> <span class="o">=</span> <span class="n">speech_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[:</span><span class="mi">45</span><span class="p">]</span>
<span class="n">test_speech_df</span> <span class="o">=</span> <span class="n">speech_df</span><span class="o">.</span><span class="n">iloc</span><span class="p">[</span><span class="mi">45</span><span class="p">:]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    

    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">tv</span> <span class="o">=</span> <span class="n">TfidfVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">stop_words</span><span class="o">=</span><span class="s1">'english'</span><span class="p">)</span>

<span class="c1"># Fit the vectorizer and transform the data</span>
<span class="n">tv_transformed</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">train_speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Transform test data</span>
<span class="n">test_tv_transformed</span> <span class="o">=</span> <span class="n">tv</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">test_speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Create new features for the test set</span>
<span class="n">test_tv_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">test_tv_transformed</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> 
                          <span class="n">columns</span><span class="o">=</span><span class="n">tv</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span><span class="o">.</span><span class="n">add_prefix</span><span class="p">(</span><span class="s1">'TFIDF_'</span><span class="p">)</span>
<span class="n">test_tv_df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_html rendered_html output_subarea output_execute_result">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>TFIDF_action</th>
      <th>TFIDF_administration</th>
      <th>TFIDF_america</th>
      <th>TFIDF_american</th>
      <th>TFIDF_authority</th>
      <th>TFIDF_best</th>
      <th>TFIDF_business</th>
      <th>TFIDF_citizens</th>
      <th>TFIDF_commerce</th>
      <th>TFIDF_common</th>
      <th>...</th>
      <th>TFIDF_subject</th>
      <th>TFIDF_support</th>
      <th>TFIDF_time</th>
      <th>TFIDF_union</th>
      <th>TFIDF_united</th>
      <th>TFIDF_war</th>
      <th>TFIDF_way</th>
      <th>TFIDF_work</th>
      <th>TFIDF_world</th>
      <th>TFIDF_years</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>0.000000</td>
      <td>0.029540</td>
      <td>0.233954</td>
      <td>0.082703</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.022577</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.115378</td>
      <td>0.000000</td>
      <td>0.024648</td>
      <td>0.079050</td>
      <td>0.033313</td>
      <td>0.000000</td>
      <td>0.299983</td>
      <td>0.134749</td>
    </tr>
    <tr>
      <th>1</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.547457</td>
      <td>0.036862</td>
      <td>0.000000</td>
      <td>0.036036</td>
      <td>0.000000</td>
      <td>0.015094</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.019296</td>
      <td>0.092567</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.052851</td>
      <td>0.066817</td>
      <td>0.078999</td>
      <td>0.277701</td>
      <td>0.126126</td>
    </tr>
    <tr>
      <th>2</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.126987</td>
      <td>0.134669</td>
      <td>0.000000</td>
      <td>0.131652</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.0</td>
      <td>0.046997</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>0.075151</td>
      <td>0.000000</td>
      <td>0.080272</td>
      <td>0.042907</td>
      <td>0.054245</td>
      <td>0.096203</td>
      <td>0.225452</td>
      <td>0.043884</td>
    </tr>
    <tr>
      <th>3</th>
      <td>0.037094</td>
      <td>0.067428</td>
      <td>0.267012</td>
      <td>0.031463</td>
      <td>0.039990</td>
      <td>0.061516</td>
      <td>0.050085</td>
      <td>0.077301</td>
      <td>0.0</td>
      <td>0.000000</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.098819</td>
      <td>0.210690</td>
      <td>0.000000</td>
      <td>0.056262</td>
      <td>0.030073</td>
      <td>0.038020</td>
      <td>0.235998</td>
      <td>0.237026</td>
      <td>0.061516</td>
    </tr>
    <tr>
      <th>4</th>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.221561</td>
      <td>0.156644</td>
      <td>0.028442</td>
      <td>0.087505</td>
      <td>0.000000</td>
      <td>0.109959</td>
      <td>0.0</td>
      <td>0.023428</td>
      <td>...</td>
      <td>0.0</td>
      <td>0.023428</td>
      <td>0.187313</td>
      <td>0.131913</td>
      <td>0.040016</td>
      <td>0.021389</td>
      <td>0.081124</td>
      <td>0.119894</td>
      <td>0.299701</td>
      <td>0.153133</td>
    </tr>
  </tbody>
</table>
<p>5 rows × 100 columns</p>
</div>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h2 id="N-grams">
<a class="anchor" href="#N-grams" aria-hidden="true"><span class="octicon octicon-link"></span></a>N-grams<a class="anchor-link" href="#N-grams"> </a>
</h2>
</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Using-longer-n-grams">
<a class="anchor" href="#Using-longer-n-grams" aria-hidden="true"><span class="octicon octicon-link"></span></a>Using longer n-grams<a class="anchor-link" href="#Using-longer-n-grams"> </a>
</h3>
<p>So far you have created features based on individual words in each of the texts. This can be quite powerful when used in a machine learning model but you may be concerned that by looking at words individually a lot of the context is being ignored. To deal with this when creating models you can use n-grams which are sequence of n words grouped together. For example:</p>
<ul>
<li>bigrams: Sequences of two consecutive words</li>
<li>trigrams: Sequences of two consecutive words</li>
</ul>
<p>These can be automatically created in your dataset by specifying the ngram_range argument as a tuple <code>(n1, n2)</code> where all n-grams in the <code>n1</code> to <code>n2</code> range are included.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cv_trigram_vec</span> <span class="o">=</span> <span class="n">CountVectorizer</span><span class="p">(</span><span class="n">max_features</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> 
                                 <span class="n">stop_words</span><span class="o">=</span><span class="s1">'english'</span><span class="p">,</span> 
                                 <span class="n">ngram_range</span><span class="o">=</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">))</span>

<span class="c1"># Fit and apply trigram vectorizer</span>
<span class="n">cv_trigram</span> <span class="o">=</span> <span class="n">cv_trigram_vec</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">speech_df</span><span class="p">[</span><span class="s1">'text_clean'</span><span class="p">])</span>

<span class="c1"># Print the trigram features</span>
<span class="n">cv_trigram_vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">()[:</span><span class="mi">10</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>['ability preserve protect',
 'agriculture commerce manufactures',
 'america ideal freedom',
 'amity mutual concession',
 'anchor peace home',
 'ask bow heads',
 'best ability preserve',
 'best interests country',
 'bless god bless',
 'bless united states']</pre>
</div>

</div>

</div>
</div>

</div>
    

<div class="cell border-box-sizing text_cell rendered">
<div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<h3 id="Finding-the-most-common-words">
<a class="anchor" href="#Finding-the-most-common-words" aria-hidden="true"><span class="octicon octicon-link"></span></a>Finding the most common words<a class="anchor-link" href="#Finding-the-most-common-words"> </a>
</h3>
<p>Its always advisable once you have created your features to inspect them to ensure that they are as you would expect. This will allow you to catch errors early, and perhaps influence what further feature engineering you will need to do.</p>

</div>
</div>
</div>
    
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">cv_tri_df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">cv_trigram</span><span class="o">.</span><span class="n">toarray</span><span class="p">(),</span> 
                        <span class="n">columns</span> <span class="o">=</span> <span class="n">cv_trigram_vec</span><span class="o">.</span><span class="n">get_feature_names</span><span class="p">())</span><span class="o">.</span><span class="n">add_prefix</span><span class="p">(</span><span class="s1">'Counts_'</span><span class="p">)</span>

<span class="c1"># Print the top 5 words in the sorted output</span>
<span class="n">cv_tri_df</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span><span class="o">.</span><span class="n">sort_values</span><span class="p">(</span><span class="n">ascending</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>Counts_constitution united states    20
Counts_people united states          13
Counts_preserve protect defend       10
Counts_mr chief justice              10
Counts_president united states        8
dtype: int64</pre>
</div>

</div>

</div>
</div>

</div>
    

</div>



  </div><!-- from https://github.com/utterance/utterances -->
<script src="https://utteranc.es/client.js"
        repo="goodboychan/goodboychan.github.io"
        issue-term="title"
        label="blogpost-comment"
        theme="github-light"
        crossorigin="anonymous"
        async>
</script><a class="u-url" href="/python/datacamp/machine_learning/2020/07/12/04-Dealing-with-Text-Data.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>An easy to use blogging platform with support for Jupyter Notebooks.</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/goodboychan" title="goodboychan"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#github"></use></svg></a></li><li><a rel="me" href="https://www.linkedin.com/in/chanseokk" title="chanseokk"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#linkedin"></use></svg></a></li><li><a rel="me" href="https://twitter.com/fastdotai" title="fastdotai"><svg class="svg-icon grey"><use xlink:href="/assets/minima-social-icons.svg#twitter"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
